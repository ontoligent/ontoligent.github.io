{"title":"The History of Data Science: 1963 to 2012","markdown":{"yaml":{"editor":{"markdown":{"wrap":72}}},"headingText":"The History of Data Science: 1963 to 2012","containsRefs":false,"markdown":"\n\n\nR.C. Alvarado\n\n# Abstract\n\n::: {#abstract}\nConsensus on the definition of data science remains low despite the\nwidespread establishment of academic programs in the field and continued\ndemand for data scientists in industry. Definitions range from rebranded\nstatistics to data-driven science to the science of data to simply the\napplication of machine learning to so-called big data to solve real\nworld problems. Current efforts to trace the history of the field in\norder to clarify its definition, such as Donoho's \"50 Years of Data\nScience\" [@donoho2017], tend to focus on a short period when a small\ngroup of statisticians adopted the term in an unsuccessful attempt to\nrebrand their field in the face of the overshadowing effects of\ncomputational statistics and data mining. Using textual evidence from\nprimary sources, this essay traces the history of the term to the early\n1960s, when it was first used by the US Air Force in a surprisingly\nsimilar way to its current usage, to 2012, the year that *Harvard\nBusiness Review* published the enormously influential article \"Data\nScientist: The Sexiest Job of the 21^st^ Century\" [@davenport2012], even\nas the American Statistical Association acknowledged a profound\n\"disconnect\" between statistics and data science. Among the themes that\nemerge from this review are (1) a continuous and consistent meaning of\ndata science as the practice of managing and processing scientific data\nfrom the 1960s to the present, (2) a long-standing opposition between\ndata analysts and data miners that has animated the field since the\n1980s, and (3) the phenomenon of \"data impedance\"---the disproportion\nbetween surplus data, indexed by phrases like \"data deluge\" and \"big\ndata,\" and the limitations of computational machinery and methods to\nprocess them. This persistent condition appears to have motivated the\nuse of the term and the field itself since its beginnings.\n:::\n\n# Introduction\n\n::: epigraph\nThe interests of data scientists---the information and computer\nscientists, database and software engineers and programmers,\ndisciplinary experts, curators and expert annotators, librarians,\narchivists, and others, who are crucial to the successful management of\na digital data collection---lie in having their creativity and\nintellectual contributions fully recognized.\n\nNational Science Board, \"Long-Lived Digital Collections: Enabling\nResearch and Education in the 21st Century\" [@simberloff2005: 27].\n:::\n\nData science today is characterized by a paradox. The large number and\nrapid growth of job opportunities and academic programs associated with\nthe field over the past decade suggest that it has matured into an\nestablished field with a recognizable body of knowledge. Yet consensus\non the definition of data science remains low. Members and observers of\nthe field possess widely variant understandings of data science,\nresulting in divergent expectations of the knowledge, skill sets, and\nabilities required by data scientists. Definitions, when they are not\nlaundry lists, range from a rebranded version of statistics to\ndata-driven science to the science of data to simply the application of\nmachine learning to so-called big data to solve real world problems.\nThese differences cannot be reduced to so-called semantics; they reflect\na range of deep-seated institutional commitments and values, as well as\nvariant understandings about the nature of knowledge and science. The\nlack of shared understanding poses a significant problem for academic\nprograms in data science: it inhibits the development of standards and a\nprofessional community, confounds the allocation of resources, and\nthreatens to undermine the authority and long-term prospects of these\nprograms.\n\nThis essay approaches the problem of defining data science by describing\nhow the collocation \"data science,\" and its grammatical variants \"data\nsciences\" and \"data scientist,\" have been used\nhistorically.[^ds-from-1963-to-2012-1] The primary method employed is\nthe close reading and precise seriation of textual evidence drawn from a\nrepresentative collection of primary sources, including organizational\nreports, academic articles, news stories, advertisements, and other\ncontemporary forms of evidence. These are used to trace the history of\nthe term's social and institutional contexts of use as well as its\ndenotative and connotative meanings. Extensive extracts are often\npresented, rather than paraphrased, as these in many cases provide the\nreader with direct and illuminating evidence for the meanings in\nquestion.[^ds-from-1963-to-2012-2]\n\n[^ds-from-1963-to-2012-1]: In this essay, a collocation is defined as a\n    combination of two or more words that function as a lexical unit. In\n    contrast to a mere n-gram, its usage tends to be idiomatic and\n    non-random. Etymologically, the usage of a collocation often begins\n    as a marked construction, by means of quotes and hyphens, before\n    eventually becoming idiomatic. Often, a collocation becomes so\n    common that it becomes a single word. For example, the word\n    \"database\" began as \"data base\" and \"data-base\" before evolving into\n    its current form (after beating out \"data bank\"). Throughout this\n    essay, the collocation \"data science\" is referred to as a term or\n    phrase, reflecting its unitary semantic status.\n\n[^ds-from-1963-to-2012-2]: The arguments and observations made by the\n    authors in each case are represented in historical tense, not the\n    textual present, which is the usual custom in writing about the\n    history of ideas. For example, instead of saying that \"Tukey argues\n    P\" in an essay from the 1960s, the evidence is presented as \"Tukey\n    argued P.\" This is done in order to ground the evidence in its\n    social and historical setting.\n\nThis historiography is presented as a series of decades in which the\nterm takes on a new meaning, beginning with its initial usage in the\n1960s and ending around 2012, when the phrase becomes a commonplace. It\nis shown that the phrase has a continuous and consistent usage\nthroughout this history. As usage of the phrase evolved, its meanings\nwere always additions to and inflections on prior meanings; in no case\ndid newer usages completely contradict what preceded them, nor did they\nappear as cases of random independent invention.\n\nThe result is a picture of the transformation of a semantic complex that\nindexes a consistent set of technical, social, and cultural realities\nthat constitute what may be called the situation of data science, a\nsituation that motivates the writing of this essay. Anticipating\nfollow-up research to this essay, this situation has been described\nrepeatedly by data scientists of all stripes as a kind of data\nprocessing *pipeline*, a sequence of operations that begins with the\nconsumption of data and ends with the production of data products,\nranging from research results and visualizations to software services\nemployed by various sectors of society.\n\n# A Note on Method\n\nIt is recognized that to trace the history of a term is insufficient to\nrepresent the full history of what that term indexes. In this case, the\nterm indexes a complex assemblage of concepts, tools, and practices that\ncharacterize data science today, many of which clearly precede or\nparallel the use of the term. Nevertheless, the exercise serves as a\nvaluable starting point from which to develop a complete historical\naccount, since finding textual examples for a phrase's string is\nrelatively easy using textual databases, and because any related fields,\nsuch as operations research or data analysis or computational\nstatistics, will be found to intersect with the term and may be pursed\nseparately.\n\nMore important, although phrases like \"data science\" are, like all\nlinguistic signs, arbitrary, they acquire motivation when they function\nas banners or brands under which allegiances are formed, catalyzing\npotential affiliations into actual ones. Such phrases are socially\nembedded speech acts with perlocutionary effects---they do not merely\ndescribe things in the world, they also instantiate them through their\nusage by agents, who influence the formation of their referents. This\nhelps to explain why, once the phrase began to trend after 2008, many\nwho previously would not affiliate themselves with the term began doing\nso, initiating a preferential attachment process to the term and thereby\ncomplexifying its definition. It also explains the purpose of efforts to\ndefine the field of data science, or to explain it away: each definition\nhas a prescriptive dimension, since by proposing a \"correct\" definition,\nit attempts to influence usage and the field it denotes. The present\nessay is no exception.\n\n::: bourdieu\nAnother reason for beginning with a history of words, via their traces\nas character strings, is that in historical research it is much easier\nto study words than the things they stand for, although we often\n(conveniently) forget this relationship and conflate the two, believing\nwe can easily move from language to the world. In our perceptions of the\nworld beyond the ken of our immediate experience---and even there---we\nare enmeshed in language to a greater degree than we may like to admit.\nWords in the form of written documents (texts) constitute the primary\nsource of data on which the construction of historical understanding\ndepends. So, even though one may wish to get past words and study things\nas they are, the fact that these things are in the past, and mainly\nrepresented to us through documents and other material traces, means\nthat one must begin with these. Ultimately, however, the purpose of\nworking with written records is to get at the things they stand for and\nindex, much as quantitative data $\\mathcal{D}$ are used to construct an\nhypothesis $\\theta$ to explain their existence. We may regard this phase\nof work as similar to the Bayesian task of establishing likelihoods and\npriors on the way to estimating posteriors.[^ds-from-1963-to-2012-3]\n:::\n\n[^ds-from-1963-to-2012-3]: This is more than an analogy. If we think of\n    the work of textual interpretation on which historical research\n    depends in a probabilistic framework, we may express the hermeneutic\n    relationship between words $Sr$ and meanings $Sd$ as follows:\n\n    $$P\\left( Sd \\middle| Sr \\right) = \\frac{P(Sd)P\\left( Sr \\middle| Sd \\right)}{P(Sr)}$$\n\n    Inasmuch as $Sr$ and $Sd$---Saussure's *signifier* and\n    *signifed*---represent what Schleiermacher called the \"linguistic\"\n    and \"psychological\" aspects of interpretation, the formula also\n    expresses the logic of the hermeneutic circle as a matter of\n    updating the prior and recomputing the posterior (Palmer 1969). The\n    analogy between the Bayesian approach to causality and the\n    hermeneutic approach to meaning has been noted by others (Groves\n    2018; Friston and Frith 2015; Ma 2015; Reason and Rutten 2018; Frank\n    and Goodman 2012).\n\nIt is helpful to understand the larger theoretical lens through which\nthese methods are applied and this history is presented and interpreted.\nThe primary assumption is that science and all forms of knowledge\nproduction are cultural systems, in the sense proposed by Clifford\nGeertz and others [@geertz2017; @martin1998]. To locate science within\nculture is not to affirm or deny the objectivity of science, or its\neffectiveness relative to other ways of knowing, but simply to assert\nthat science, like all human endeavors, is made possible in and through\nsocial interaction over time and space through the media forms that make\nsuch interaction possible. Among these media forms the most significant\nis language. Given this, I adopt a discourse-centered approach to\nunderstanding culture [@urban1993]. Further, as a means to theorize the\ncausal relationship between language and world, I adopt the view that\ndiscourse---spoken and written language, as opposed to generative\ngrammar---is best understood as situated action [@mills1940;\n@suchman1987; @norman1993]. In this view, language does not simply refer\nto the world, but participates in it, as a resource that enables\ndistributed cognition and produces effects through its use in concrete\nsituations. From an interpretive perspective, the meanings of words\nindex the work they perform. This essentially causal conception of\nlanguage use allows us to make sense of the relationship between phrases\nlike \"data science\" and the human endeavors with which they are\nassociated, the posterior relationship encoded in the Bayesian framework\ndescribed above.\n\nFinally, no claims are made for having discovered the first actual\nusages of the term in question, neither at its origin nor during any of\nits transformations. Instead, the documentary record that comprises the\nsum of databases and documents, both digital and material, available to\nthe author is regarded as a kind of film, or an archaeological\nsettlement pattern, on which collective verbal behavior impinges and\nleaves its marks. It is likely to be incomplete, but also comprehensive\nenough to capture patterns to a degree of resolution high enough to\nsupport the claims being made.\n\n# Historical Sequence\n\n## The 1960s\n\nThe first uses of the phrase \"data science,\" as a recognizable\ncollocation, appeared in the early 1960s in both singular and plural\nforms. Two main uses are found in the written record almost\nsimultaneously, one in a military context, the other industrial. In both\ncases, the phrase functioned as an organizational rubric for a new kind\nof labor associated with the rise of large-scale data generating and\nprocessing technologies that were the hallmark of the postwar era.\n\nThe military use first appeared in a series of reports covering the\nperiod from July 1962 to June 1970 on research carried out by the Data\nSciences Laboratory (DSL). The DSL was founded in 1963 as one of several\nlabs associated with the US Air Force Cambridge Research Laboratories\n(AFCRL).[^ds-from-1963-to-2012-4] These reports do not provide an\nexplicit definition of data science or a rationale for choosing the\nexpression over others, but its meaning is clear from context. Consider\nthe stated motivation for the lab---which, as one of the first attested\nuses of the phrase, is worth quoting at length:\n\n[^ds-from-1963-to-2012-4]: The DSL was formed by combining the Computer\n    and Mathematical Sciences Laboratory and the Communications Sciences\n    Laboratory in the 1963 reorganization (Venkateswaran 1963: 628).\n    Within the AFCRL, the lab was noted for its \"research on speech\n    patterns \\[which\\] dated back to the 1940's \\[sic\\]\" (Altshuler\n    2013: 27-28).\n\n> The most striking common factor in the advances of the major\n> technologies during the past fifteen years \\[i.e. since WWII\\] is the\n> increased use and exchange of information. *Modern data processing and\n> computing machinery, together with improved communications*, has made\n> it possible to ask for, collect, process and use *astronomical\n> amounts* of detailed data. ...\n>\n> But in the face of this progress there is impatience with *the\n> limitations of existing machines*. ...\n>\n> A large number of military systems---for example, those concerned with\n> surveillance and warning, command and control, or weather\n> prediction---deal in *highly perishable information*. Few existing\n> computers are capable of handling this information in\n> \"real-time\"---that is, processing the data as they come in. Higher\n> speed is one way to a solution. But increased speed will not overcome\n> fundamental shortcomings of existing computers. These shortcomings\n> arise from the fact that existing machines, having essentially evolved\n> as numerical calculators, are not always optimally organized to\n> perform the tasks they are called upon to do. ...\n>\n> ... *A considerable amount of the data to be processed is not\n> numerical*. It is in audio or visual form. Immense amounts of visual\n> data---for example, TIROS satellite pictures or bubble chamber\n> pictures of atomic processes---remain unevaluated for lack of\n> processing capability. In part this is due to the fact that, from the\n> data processing point of view, the information content of pictorial\n> inputs is highly redundant, *demanding excessive channel capacity* in\n> transmission and compelling processing machinery to handle vast\n> amounts of meaningless or non-essential information. Similar\n> considerations prevail for speech. ...\n>\n> In real-life situations *data are almost never available in\n> unadulterated form*, but are usually distorted or masked by spurious\n> signals. Examples are seismic data, radio propagation measurements,\n> radar and infrared surveillance data and bioelectric signals. ...\n>\n> An increasing amount of *data processing research* is aimed at the\n> creation of machines or machine programs that incorporate features of\n> *deductive and inductive reasoning, learning, adaptation, hypothesis\n> formation and recognition*. Such features are commonly associated with\n> human thought processes and, when incorporated in machines, are\n> frequently termed \"artificial intelligence.\" Artificial intelligence\n> is of utmost importance in decision situations where not all possible\n> future events can be foreseen [@afcrl1963; emphasis added].\n\nThe two later reports are more succinct:\n\n> The program of the Data Sciences Laboratory centers on the processing,\n> transmission, display and use of information. Implicit in this program\n> statement is an emphasis on computer technology [@afcrl1967: 13].\n>\n> Broadly defined, the program of the Data Sciences Laboratory involves\n> the automatic processing, filtering, interpretation and transmission\n> of information [@afcrl1970: 318].\n\nBased on these excerpts alone, one could be forgiven for inferring that\ndata science was invented by the US Air Force around 1963 with the\nformation of the DSL. Most of the elements currently considered central\nto the field were brought together there: a concern for processing what\nis later called \"big data,\" clearly defined in terms of volume,\nvelocity, and variety (and volatility); a recognition of the fundamental\nmessiness of data; and a focus on artificial intelligence as an\nessential approach to extract value from such data. The lab produced\nsignificant research on pattern recognition and classification, machine\nlearning, neural networks, and spoken language processing in the service\nof processing the novel forms of data described above.\n\n::: comment\nInsert here description of example projects. Pattern recognition of\nplanes and letters, extracting linguistic features from voice, the idea\nof \"dynamic data processing,\" and the DX-1.\n:::\n\nMore important than locating a precise time and place for the origin of\nthe field---a task doomed to fail, given the complexity and\nmultithreaded nature of historical phenomena---is the work of describing\nthe historical situation within which the phrase data science developed\nand which it indexes. A clue to this context is the repeated emphasis on\ndata and information processing we find in the DSL's descriptions of its\nwork. Specifically, the phrases \"the data processing point of view\" and\n\"data processing research\" index a set of military projects and concerns\nassociated with the early Cold War.\n\nThe AFCRL was originally established in 1945 as the Cambridge Field\nStation, a unit created to hold onto the Harvard and MIT scientists and\nengineers who performed significant research on radar and electronics in\nWWII. During the 1950s, the lab focused on Project Lincoln, which led to\nthe creation of the Semi-Automatic Ground Environment (SAGE), a\nreal-time command-and-control system developed to counter to perceived\nthreat of an airborne nuclear attack by the Soviet Union. As a\ncontinental air defense system, SAGE was designed to collect, analyze,\nand relay data from a vast array of geographically distributed radars in\nreal-time, in order to initiate an effective response to an aerial\nattack. At the heart of the system was a network of large digital\ncomputers that coordinated the data retrieved from the radar sites over\nphone lines and processed them to produce a single unified\nimage---literally displayed on a monitor---of the airspace over a wide\narea.\n\nAlthough responsibility for research on such military surveillance\nsystems was moved out of the lab in 1961, just before the Data Sciences\nLab was formed, it is plausible that the SAGE project influenced the\nmission of the lab by providing a concrete paradigm for a new kind of\ninformation processing situation. This was the situation of using of\nadvanced computational machinery and state-of-the-art data reduction and\npattern recognizing methods to process vast amounts of real-time signal\ndata, coming from geographically distributed radars and satellites, in\norder to represent a complex space of operations and guide making\ndecisions about how to operate in that space. The paradigm was also\napplied to the problem of weather forecasting and other geophysical\ndomains. (If we replace radars with smart phones and the Internet of\nThings, it is not difficult to draw a parallel between this arrangement\nand that of social media corporations today.)\n\nEvidence for the influence of radar and satellite-based real-time\ncommand and control systems on the conceptualization of data science may\nbe found in the idioms we currently associate with the field, such as\nthe use of \"signal and noise\" to refer to the presence and absence of\nstatistically significant patterns and the use of Receiver Operator\nCharacteristic (ROC) curves---first used by military radar operators in\n1941---to measure the performance of binary classifiers. Other idioms,\nsuch as \"data deluge,\" also emerge in this context. A history of the\nexpression data deluge is worth its own study, but it is clear that its\nprovenance was the situation described above. The term gained currency\nin the 1960s in reference to satellite data collected by NASA and the\nmilitary. Consider this passage from the NASA publication *Scientific\nSatellites*:\n\n> The data deluge, information flood, or whatever you choose to call it,\n> is hard to measure in common terms. An Observatory-class satellite may\n> spew out more than 10^11^ data words during its lifetime, the\n> equivalent of several hundred thousand books. Data-rate projections,\n> summed for all scientific satellites, prophesy hundreds of millions of\n> words per day descending on Earth-based data processing centers. These\n> data must be translated to a common language, or at least a language\n> widely understood by computers (viz, PCM), then edited, cataloged,\n> indexed, archived, and made available to the scientific community upon\n> demand. Obviously, the vaunted information explosion is not only\n> confined to technical reports alone, but also to the data from which\n> they are written. In fact, the quantity of raw data generally exceeds\n> the length of the resulting paper by many orders of magnitude\n> [@corliss1967: 157].[^ds-from-1963-to-2012-5]\n\n[^ds-from-1963-to-2012-5]: Preceding the usage of data deluge and in a\n    wider context is \"information explosion.\" Both expressions conjure\n    images of disaster and have been remarkably persistent up to the\n    present era. Only with the coining of \"big data\" have they been\n    displaced by a more positive term.\n\nWork on such projects generated an enormous amount of research on the\nproblems arising from the processing and interpreting data. In the\npreceding text, the author describes this work in some detail,\nspecifying a series of stages in which data are transformed into a form\nsuitable for scientific analysis. We would recognize this work today as\ndata wrangling. It is reasonable to infer that the concept of data\nscience emerged to designate this kind of work, which, in any case, is\nconsistent with the published mission of the Data Sciences Lab.\n\n::: comment\nIt may be appropriate to include here a discussion of the DX-1 (instead\nof above). The DX-1 generalizes the logic of the SAGE system, which in\nturn computerizes (informates?) the OR paradigm developed during the\nBattle of Britain.\n:::\n\nPrior to the formation of the DSL, the phrase \"data-processing\nscientist\" was in use to designate the work involved in data reduction\ncenters, such as the one built at the Langley Aeronautical Lab in\nVirginia to process the enormous amounts of data generated by wind\ntunnel experiments and other sources associated with the nascent space\nprogram. Data reduction was essential to projects like SAGE, in which\nvast amounts of real-time signal data had to be reduced prior to\nanalysis. In a House appropriations hearing in 1958, the following\ndescription of this kind of work was provided by Dr. James H.\nDoolittle,[^ds-from-1963-to-2012-6] the last chairman of NACA before it\nbecame NASA:\n\n[^ds-from-1963-to-2012-6]: This is the very same General Doolittle of\n    Doolittle's Raid.\n\n> The data processing function is much more complex than the mere\n> production line job of translating raw data into usable form. Each new\n> research project must be reviewed to determine how the data will be\n> obtained, what type and volume of calculations are required, and what\n> modifications must be made to the recording instruments and\n> data-processing apparatus to meet the requirements. *It may even be\n> necessary for the data-processing scientist to design and construct\n> new equipment for a new type of problem.* Some projects cannot be\n> undertaken until the specific means of obtaining and handling the data\n> have been worked out. In some research areas, on-line service to a\n> data processing center saves considerable time by allowing the project\n> engineer to obtain a spot check on the computed results while the\n> facility is in operation. This permits him to make an immediate change\n> in the test conditions to obtain the results that he wants\n> [@appropriations1958: emphases added].\n\n### Impedance\n\nThe kind of work conducted by NASA and the Air Force in this period\nprovides a context for understanding the meaning of data science when\nthe phrase first appeared. In this context, data science designated a\nkind of research focused on what we may call the *impedance* that arises\nfrom the ever-growing requirements of data produced by an expanding\narray of signal generating technologies (e.g. radars and satellites),\nscientific instruments, and reports on one hand, and the limited\ncapacity of computational machinery to process these on the other. It is\nconcerned specifically with the development of computational methods and\ntools to handle the problems and harness the opportunities posed by\nsurplus data. In this context, *data science is the science of\nprocessing and extracting value from data by means of computation*.\nAlthough the specific technologies have changed continually, the\ncondition of data impedance, the disproportion between data abundance\nand computational scarcity relative to the need to extract value from\nthe data, has been constant since this time, and defines the condition\nthat gives rise to data science in this sense.\n\nThis interpretation of the meaning of data science is corroborated by\nother contemporary usages. A report on a US Department of Defense\nprogram to define standards \"to interchange data among independent data\nsystems\" refers to a \"Data Science Task Group\" established in 1966 \"to\nformulate views of data and definitions of data terms that would meet\nthe needs of the program\" [@crawfordjr.1974: 51]. Crawford, a fellow\nstudent of Claude Shannon at MIT under Vannevar Bush, was affiliated\nwith IBM's Advanced Systems Development Division, a group that had\ndeveloped optical scanners to recognize handwritten numbers in 1964. In\naddition, the term appeared in the trademarked name of at least two\ncorporations in the United States: Data Science Corporation, formed in\n1962 by a former IBM employee [@roberta], and Mohawk Data Sciences,\nfounded in 1964 by a three former UNIVAC engineers [@mohawkd1966]. Both\ncompanies provided data processing services and lasted well into the era\nof personal computing. In the late 1960s and 1970s, many other companies\nused term as well, such as Data Science Ventures [@mortcollinsventures]\nand Carroll Data Science Corporation\n[@office1979].[^ds-from-1963-to-2012-7]\n\n[^ds-from-1963-to-2012-7]: This continues into the 1980s, with Gateway\n    Data Sciences Corp and Vertex Data Science, Ltd.\n\n### Meaning of \"data\" and the information crisis\n\nLet us consider the meaning and significance of the word \"data\" in these\nexamples, especially given the DOD's concern to define it, as a clue for\nthe motivation of the term \"data science\" when other candidates, such as\ncomputer science and information science, might have sufficed at the\ntime. The choice of the term appears to be motivated by a concern to\ndefine and understand *data* itself as an object of study, a\nsurprisingly opaque concept that is thrown into sharp relief in the\ncontext of getting computers to do the hard work of processing\ninformation in the context of impedance, as a result of their\ncommercialization and widespread use in science, industry, and\ngovernment. Thus although the term \"data\" has a long history---deriving\nfrom the Latin word for that which is *given* in the epistemological\nsense, either through the senses, reason, or authority---in this context\nit refers to the structured and discrete representation of information\nsources so that these may be processed by computers. In other words,\n*data is machine readable information*.[^ds-from-1963-to-2012-8] It\nfollows that the data sciences in this period are concerned with\nunderstanding machine readable information, in terms of how to represent\nit and how to process it in order to extract value.\n\n[^ds-from-1963-to-2012-8]: Preceding the usage of data deluge and in a\n    wider context is \"information explosion.\" Both expressions conjure\n    images of disaster and have been remarkably persistent up to the\n    present era. Only with the coining of \"big dat\n\nFurther evidence of this concern for what might be called the\ninformation crisis in scientific research---and for the idea that the\nsolution to this crisis hinges on refining the concept of data---can be\nfound in the formation of the International Council for Science (ICSU)\nCommittee on Data for Science and Technology (CODATA) in 1966. This\norganization was established by an international group of physicists\nalarmed that the \"deluge of data was swamping the traditional\npublication and retrieval mechanisms,\" and that this posed \"a danger\nthat much of it would be lost to future generations\"\n[@lide2012]. Importantly, CODATA still exists and currently identifies\nitself with the field of data science. In 2001 it launched the *Data\nScience Journal,* focused on \"the management, dissemination, use and\nreuse of research data and databases across all research domains,\nincluding science, technology, the humanities and the arts\" (*Data\nScience Journal* n.d.). Aware that the definition of the field had\nchanged significantly since its founding, the journal provided the\nfollowing clarification in 2014:\n\n> We primarily want to *specify* our definition of \"data science\" as the\n> classic sense of the science of data practices that advance human\n> understanding and knowledge---the evidence-based study of the\n> socio-technical developments and transformations that affect science\n> policy; the conduct and methods of research; and the data systems,\n> standards, and infrastructure that are integral to research.\n>\n> We recognize the contemporary emphasis on data science, which is more\n> concerned with data analytics, statistics, and inference. We embrace\n> this new definition but seek papers that focus specifically on the\n> data concerns of an application in analytics, machine learning,\n> cybersecurity or what have you. We continue to seek papers addressing\n> data stewardship, representation, re-use, policy, education etc.\n>\n> Most importantly, we seek broad lessons on the science of data.\n> Contributors should generalize the significance of their contribution\n> and demonstrate how their work has wide significance or application\n> beyond their core study [@parsons2019; emphasis in original].\n\nThis retrospective definition supports the idea that data science in the\n1960s---which we may call, following this note, classical data\nscience---was concerned with understanding data practices, where data is\nunderstood to be a universal medium into which information in a variety\nof native forms, from scientific essays to radio signals from outer\nspace, must be encoded so that it may be shared and processed. Data\nscience as \"the science of data practices that advance human\nunderstanding and knowledge\" is concerned with defining and inventing\nthis medium, it's structure and function.\n\n### A Note on Tukey\n\nTukey's famous essay on data analysis, which appears during the same\ntime period, touches on some of the drivers noted here, such as the high\nvolume and spottiness of real data and the impact of the computer, but\nfrom the perspective of advanced mathematical statistics [@tukey1962].\nOne difference between his view and that adopted by the AFCRL is of\ninterest here: whereas Tukey appears to have regarded the computer as a\nmore or less fixed technology, replaceable in many tasks by \"pen, paper,\nand slide rule\" but irreplaceable (he conceded) in others, the Data\nSciences Lab viewed the computer as a fluid technology, one that needed\nto be pushed beyond its original design envelope as a numerical\ncalculator. In fact, the AFCRL and similar groups appear to have\nprovided the impetus to move computer science beyond a concern for\nabstract algorithms and to include the study of data structures and\ntechnologies, specifically databases. It is, as we shall see, a\ndifference that continues to underlie current disputes over the meaning\nand value of data science.\n\n::: comment\nHere include the extent of usage of the term\n\n-   The VA\n-   WSMR\n-   Dynalectron\n:::\n\n## The 1970s\n\nIt is clear that by the early 1970s the term data science had been in\ncirculation in several contexts and referred to ideas and tools relating\nto computational data processing. Importantly, these usages were not\nobscure---the AFCRL was one of the premier research laboratories in the\nworld and closely connected with Harvard and MIT [@altshuler2013], an\ninternational cross-roads of intellectual life where many would have\ncome into contact with the term. Similarly, IBM and UNIVAC, the sources\nof the founders of two self-proclaimed data science companies, were the\ntwo largest computer manufacturers at the time.[^ds-from-1963-to-2012-9]\n\n[^ds-from-1963-to-2012-9]: a\" have they been displaced by a more\n    positive term.\n\n    This is the very same General Doolittle of Doolittle's Raid.\n\n    peared in a 1964 issue of the British weekly *Nature*:\n\n    A SYMPOSIUM on \"Models for the Perception of Speech and Visual\n    Form\", sponsored by the Data Sciences Laboratory of the Air Force\n    Cambridge Research Laboratory, will be held in Boston during\n    November 11-14. Further information can be obtained from Mr. G. A.\n    Cushman, Wentworth Institute, 550 Huntington Avenue, Boston,\n    Massachusetts 02115 (\"Announcements\" 1964) (\"Announcements\" 1964).\n\nAlthough the AFCRL closed the Data Sciences Lab by\n1970,[^ds-from-1963-to-2012-10] the term continued to be used, most\nnotably by the Danish computer scientist Peter Naur, who suggested that\ncomputer science, a relatively new field, be renamed to data science.\nHis argument, consistent with previous usage, was that computer science\nis fundamentally concerned with data processing and not mere\ncomputation, i.e. what the AFCRL derided as numerical calculation.\nEarlier, in the 1960s, Naur had coined the term \"datalogy\" (Danish:\n*datalogi*) for this purpose, but later found the term data science to\nbe a suitable synonym, perhaps due to its currency or to his familiarity\nwith the DSL, which shared his research interest in developing\nprogramming languages [@naur1966; @naur1968]. In contrast to the AFCRL,\nNaur provided an explicit definition of data science:\n\n[^ds-from-1963-to-2012-10]: Altshuler writes that the lab was\n    \"abolished\" in June 1972 \"in response to a large reduction in\n    manpower authorizations\" (Altshuler 2013: 27). However, the unit is\n    not mentioned in the July 1970 to June 1972 research report (AFCRL\n    1973). The lab's closure may have been a consequence of the passing\n    of the Mansfield Amendment in 1969, which prohibited the military\n    from carrying out \"any research project or study unless such project\n    or study has a direct and apparent relationship to a specific\n    military function\" (U. S. C. H. C. on Appropriations 1970: 348).\n\n> The starting point is the concept of *data*, as defined in \\[0.7\\]:\n> DATA: *A representation of facts or ideas in a formalized manner\n> capable of being communicated or manipulated by some process.* Data\n> science is the science of dealing with data, once they have been\n> established, while the relation of data to what they represent is\n> delegated to other fields and sciences.\n>\n> The usefulness of data and data processes derives from their\n> application in building and handling models of reality.\n>\n> ...\n>\n> A basic principle of data science is this: The data representation\n> must be chosen with due regard to the transformation to be achieved\n> and the data processing tools available. This stresses the importance\n> of concern for the characteristics of the data processing tools.\n>\n> Limits on what may be achieved by data processing may arise both from\n> the difficulty of establishing data that represent a field of interest\n> in a relevant manner, and from the difficulty of formulating the data\n> processing needed. Some of the difficulty of understanding these\n> limits is caused by the ease with which certain data processing tasks\n> are performed by humans [@naur1974: 30-31; emphasis and citation in\n> original; the reference \"0.7\" refers to @ifipgui1971].\n\nClearly, Naur's definition inherits the classical definition described\nabove; it locates the meaning of the term in the series of practices\nassociated with the larger activity of data processing. These practices\ninclude establishment, choice of representation, conversion and\ntransformation, the modeling of reality, and the guiding of human\nactions. One difference is that Naur is keen to locate data science\nwithin a division of labor implied by this general process, separating\ndata science *per se* from the work of data acquisition (establishment)\nand the domain knowledge required to acquire data effectively. In this\nview, data science is more specifically concerned with the formal\nrepresentation of data (i.e. with data structures and models), a\npractice that must be done in light of how data are to be transformed\ndownstream, and with which tools (i.e. algorithms and programming\nlanguages). As we shall see, the weighting that Naur assigns to this\nkind of work is not inherited by later theorists. However, the general\nimage of a sequential process with distinct phases in the life cycle of\ndata is. Here we see the appearance of the image of a pipeline, unnamed\nbut implied by the concept of *process*, which dominates the mental\nrepresentation of the field from its origins in the 1960s.\n\nFar from being a fluke, Naur's usage developed the classical definition\nof data science initiated by NASA and the Air Force, intentionally or\nnot. The fact that his attempt to rename computer science failed outside\nof his native country (and Sweden) is not important; his understanding\nof computer science sheds light on how closely the concept of data was\n(and is) related to computation and process.\n\nIt is worth noting that Naur's definition implies a familiarity with the\nreal-world provenance of data processing in industry and government.\nIndeed, by this time computational data processing had penetrated all\nsectors of society, and the pressure to improve tools and methods to\nrepresent and process data had increased as well. As a result of this\npressure, two important data standards were developed in this period:\nCodd's relational model, which laid the foundation for SQL and\ncommercially viable relational databases in the 1980s, and Goldfarb's\nSGML, which would become a standard for encoding so-called unstructured\ntextual data (such as legal documents) and later the basis for HTML and\nXML [@codd1970 @goldfarb1970]. This focus on the human context of data\nprocessing is reflected in his later work; a volume of selections of his\nwriting from 1951 to 1990, which includes his essay on data science, is\nentitled \"Computing: A Human Activity\" [@naur1992].\n\n## The 1980s\n\n::: comment\nData Scientist becomes commonplace.\n\nTopics:\n\n-   New Scientist jobs\n-   NASA, NOAA\n\nDiscuss rise of data mining?\n:::\n\n## The 1990s\n\n### 1994: Statistical Data Science 1\n\nInterestingly, in 1977 a prefixed variant of the term does appear in the\ntitle of the technical report, \"Non-Parametric Statistical Data Science:\nA Unified Approach Based on Density Estimation and Testing for 'White\nNoise'\" [@parzen1977]. However, Parzen later publishes a version of this\nwork as \"Nonparametric Statistical Data Modeling\" [@parzen1979],\nindicating that his original word choice was mistaken. Yet the original\nchoice may not have been entirely unmotivated: Parzen's work attempts to\nunify parametric and non-parametric methods under one umbrella. Given\nthe natural inclination of mathematical statistics for the former and\ndata analysis for the latter, his choice of the term data science may\nhave signaled an attempt to encompass both approaches to data. It is\nalso worth noting that he later used to the term to introduce a \"new\nculture of statistical science called LP MIXED DATA SCIENCE\"\n[@parzen2013], after the term became popular.[^ds-from-1963-to-2012-11]\nWhether or not this unifying goal was his motivation, statisticians\nlater became quite interested in the term for precisely this reason.\n\n[^ds-from-1963-to-2012-11]: Parzen's use of the term \"culture\" here\n    echoes his comments on Breiman's famous essay on two cultures of\n    statistical models, where he suggested that there are in fact\n    several cultures, including his own, to which he devoted the\n    majority of his response (Breiman 2001: 224--226).\n\nIn the early 1990s, the term resurfaced in the context of statistics. It\nappeared in the title of a 1994 essay by the Japanese statistician\nNoburu Ohsumi on the application of hypermedia to the problem of\norganizing data, \"New Data and New Tools: A Hypermedia Environment for\nNavigating Statistical Knowledge in Data Science,\" an elaboration of an\nessay published two years earlier [@ohsumi1992;\n@ohsumi1994].[^ds-from-1963-to-2012-12] In these essays, Ohsumi\ndescribed the by now familiar litany of problems associated with data\nimpedance, although this time the focus was on the production of data\nresulting from its analysis and storage, not its consumption in\nso-called raw form:\n\n[^ds-from-1963-to-2012-12]: According to Ohsumi, \"the term 'data\n    science' appeared for the first time\" in 1992, at a research\n    exchange meeting between French and Japanese data analysts\n    (so-called) at Montpelier University II in France [@ohsumi2000:\n    331]. He also claims to have \"argued the urgency of the need to\n    grasp the concept 'data science'\" in 1992 (329).\n\n> In research organizations handling statistical information, the volume\n> of stored information resources, including research results,\n> materials, and software, is increasing to the point that conventional\n> separate databases and information management systems have become\n> insufficient to deal with the amount. Increasing diversification in\n> the media used these days interferes with the rapid retrieval and use\n> of the information needed by users. A new system that realizes a\n> presentation environment based on new concepts is needed to inform\n> potential users of the value and effectiveness of using the vast\n> amount of diverse data [@ohsumi1992: 375].\n\nFor research facilities around the world, the products of classical data\nscience---the database and data processing software---had become a\nsorcerer's apprentice, creating new problems with each solution.\nOrganizations were drowning in the data sets they produced or acquired,\nthe software used to process them, the print and digital libraries of\nreports and articles resulting from their analyses, and a host of other\nmaterials. The requirements, approach, and design goals of Ohsumi's\nproposed system, the Meta-Stat Navigator, are strikingly similar to\nthose of a contemporary system designed to solve the information\nproblems of another scientific organization: Berners-Lee's World Wide\nWeb, famously developed at CERN in 1989 [@berners-lee2008]. Of course,\nthe latter quickly obviated Ohsumi's proposal and become synonymous with\nthe Internet, invented decades earlier.\n\nThe significance of Meta-Stat for our purposes is that this kind of work\nwas understood clearly as data science at this point in history. Data\nscience continued to be connected with the processing and representation\nof data, and was distinct from data analysis, but with this important\ndevelopment: statisticians had become embedded in these technologies,\nand their work had changed significantly as a result. And, as a result\nof this change in working conditions, the connection between data\nanalysis and data science became closer.\n\nHere we may locate with some precision a crucial transformation in the\nmeaning of the term, associated with its adoption by a new set of users.\nOne clue to this change is the opportunity Ohsumi observed amid the\nchallenges posed by data deluge:\n\n> ... the information handled by the statistical sciences lies on the\n> boundaries of various other sciences and clarifies the relationships\n> and nature of information that joins these sciences. Development of a\n> system that fully organizes and integrates strategic information is\n> essential [@ohsumi1992: 375].\n\nThe Meta-Stat \"system\" was designed to realize the opportunity opened up\nby the central position statisticians had come to occupy among the\nprolifically data-generating sciences and the computational environment\nin which these data were made available. Data science, in this view, is\n*meta-statistics*, an encompassing concern for understanding data,\nunderstood as a universal medium, and its relationship to knowledge.\nThis perspective would be adopted by Ohsumi's senior compatriot and\nfellow statistician, Chikio Hayashi, whom Ohsumi described as \"the\npioneer and founder of data science\" [@ohsumi2004: 1].\n\nIn 1993, at a roundtable discussion during the fourth conference of the\nInternational Federation of Classification Societies held in Paris\n(IFCS-93), Hayashi uttered the phrase \"Data Science\" and was then asked\nto explain it. At the next conference (IFCS-96), he presented an answer,\nin addition to having the conference named to emphasize the importance\nof the term---\"Data Science, Classification, and Related Methods.\" His\ndefinition is as follows:\n\n> Data science is not only a synthetic concept to unify \\[mathematical\\]\n> statistics, data analysis and their related methods but also comprises\n> their results. It includes three phases, design for data, collection\n> of data, and analysis on data. Data science intends to analyze and\n> understand actual phenomena with \"data.\" In other words, the aim of\n> data science is to reveal the features of the hidden structure of\n> complicated natural, human and social phenomena with data from a\n> different point of view from the established or traditional theory and\n> method. This point of view implies multidimensional, dynamic and\n> flexible ways of thinking [@hayashi1998: 41].\n\nHayashi went on to describe the sequence of design, collection, and\nanalysis as a primary and iterative \"structure finding\" process in which\ndata are transformed from a state of \"diversification,\" given the\ninherent \"multifariousness\" of the phenomena they represent, to one of\n\"conceptualization or simplification\" (41). The discovery of structure\nis accomplished with what we would recognize today as the methods of\nexploratory data analysis and unsupervised learning. In effect,\nHayashi's definition abstracted the design goals of Ohsumi's Meta-Stat\nsystem and presented them as \"a new paradigm\" of science, one that would\nencompass statistics, data analysis, and their vast output of data\nwithin in a unified, process-oriented framework---data science (40).\n\nIn addition to Hayashi's own definition, it helpful also to see how the\nfield was defined by the editors (who included Hayashi) of the\nproceedings of IFCS-96:\n\n> The volume covers a wide range of topics and perspectives in *the\n> growing field of data science*, including theoretical and\n> methodological advances in domains relating to data gathering,\n> classification and clustering, exploratory and multivariate data\n> analysis, and knowledge discovery and seeking.\n>\n> It gives a broad view of the state of the art and is intended for\n> those in the scientific community who either develop new data analysis\n> methods or gather data and use search tools for analyzing and\n> interpreting large and complex data sets. Presenting a wide field of\n> applications, this book is of interest not only to data analysts,\n> mathematicians, and statisticians but also to scientists from many\n> areas and disciplines concerned with complex data: medicine, biology,\n> space science, geoscience, environmental science, information science,\n> image and pattern analysis, economics, statistics, social sciences,\n> psychology, cognitive science, behavioral science, marketing and\n> survey research, data mining, and knowledge organization\n> [@hayashi1998a: v; emphasis added].\n\nOf interest here is use of \"data science\" as a big tent, an inclusive\nrubric under which to group a series of domains (which match roughly to\na process) as well as a broad range of disciplines and levels, from tool\nbuilders to scientists and practice to theory. This passage is also\nsignificant for including within the scope of data science the methods\nof machine learning as well as data mining among the list of sciences\nconcerned with \"complex data,\" suggesting the prominence of these\napproaches at that time. We will see that not all definitions proceeding\nfrom this community were as inclusive.\n\n::: bourdieu\nHayashi assigned a revolutionary and almost messianic role to data\nscience. In his vision, the statistical sciences had lost their way.\nMathematical statisticians had come to overvalue abstract inference and\nprecision, and by choosing to work with the artificial data required to\npursue these goals were \"prone to be removed from reality\" (40). Data\nanalysts, although working with real data, had \"come to manipulate or\nhandle only existing data without taking into consideration both the\nquality of data and the meaning of data ... to make efforts only for the\nrefinement of convenient and serviceable computer software and to\nimitate popular ideas of mathematical statistics without considering the\nessential meaning\" (40). As a result of these divergent attitudes toward\ndata, and the disregard of both for the scientist's engagement with the\nprimary, existential relationship between data and phenomena, the field\nhad become stagnant and lacking in innovation. Data science emerged as a\nsavior, unifying a divided people, showing their way out of the\nwilderness, and restoring prosperity and prestige to their community.\n\nIf Hayashi's criticisms of data analysis sound familiar to those leveled\ntoday against data scientists, it is because the issues data science was\nmeant to resolve are recurring and systemic. So too is the separation\nbetween data analysis and mathematical statistics, which was recognized\nby Box, and later Tukey, in the 1970s. In his response to Parzen---who,\nwe noted, sought to overcome a methodological split between the two\nsubfields---Tukey wrote:\n\n> I concur with the general sentiments expressed by George Box in his\n> Presidential Address ... that we have great need for the whole\n> statistician in one body---for the analyst of data as well as for the\n> probability model maker---and the inferential theorist/practitioner.\n> One cannot, however, make a whole man by claiming that one can subsume\n> one important class of mental activity under another class whose style\n> and purposes are not only different but incompatible. To be \"whole\n> statisticians\" as Box might put it, or to be \"whole statistician-data\n> analysts\" as I might, means to be single persons who can take quite\n> different views and adopt quite different styles as the needs change.\n> As the title of my paper of yesterday put it, \"we need both\n> exploratory and confirmatory\"! The twain can---and should---meet, but\n> they need to remain a pair (or two distinct parts of a larger team) if\n> they are to do what they should and can [@tukey1979: 122].\n\nTukey implies a solution to the schism, later observed by Hayashi, in\nbetter organization, not in a utopian \"new man\" or in a synthetic\nscience *per se*, recalling the division of labor proposed by Naur, but\nhere focusing on different roles within that division. Implicit in this\napproach is the view that the problem with statistics was not epistemic\nbut organizational.\n\nHere it is helpful to recall a property of Kuhn's concept of\nparadigm---an obvious lens through which to observe our topic---which is\noften overlooked by those who use the term: it refers no to an abstract\nbody of ideas that succeed on the basis of their intrinsic rationality\nor truth value, but to the successful practical application of ideas by\nmeans of novel methods and tools in a way that they may be imitated. The\nconcept has both epistemic and social dimensions. Viewed in this light,\nthe question of whether data science is in fact a science---our main\nquestion---becomes a matter of determining whether it solves important\nproblems in new ways, by means of an assemblage of ideas, methods, and\ntools that may be grasped and imitated by others. Hence, although Tukey\nand Hayashi may appear to be divergent in their approaches to overcoming\nthe problems, they represent the two aspects of a scientific paradigm,\nthe one conceptual, the other practical. This should not be viewed as\ncontradictory.\n:::\n\nFollowing the IFCS meetings, as well as two meetings of the Japan\nStatistical Society that held \"special sessions on data science,''\nOhsumi developed Hayashi's definition as well as its rationale\n[@ohsumi2000: 331]. At this point, we shall call this the Tokyo school\nof data science, given the association of both Hayashi and Ohsumi with\nthe Institute of Statistical Mathematics in Tokyo, Japan. In a paper\nthat explicitly addressed the relationship between data analysis and\ndata science, and which is perhaps the first of several to claim the\nflag of data science for statistics, Ohsumi declared that because of its\nprivileging of\"mathematical methodologies\" over an engagement with data\nacquisition, data analysis had become \"a canary that has forgotten to\nsing,\" referring to a Japanese children's song that contemplates a\nsilent bird's fate (332).[^ds-from-1963-to-2012-13] Amplifying Hayashi,\nhe asserted that \"\\[h\\]ow data are gathered is the key to defining the\nrelevant information and making it easy to understand and analyze\"\n(331). In making this point, Ohsumi referred to a new figure on the\nscene, one that contradicted the principles he proposed:\n\n[^ds-from-1963-to-2012-13]: The specific reference is to a poem, later\n    set to music, written by the Japanese poet Saijoo Yaso (西条八十),\n    who lived from 1892 to 1970. According to Miriam Davis, \"The moral\n    of the song is that if the canary loses its song it is not worth its\n    existence so it should make the most of the gift of song it has been\n    given.\" [@davis]\n\n> In my opinion, this viewpoint on the meaning of data science is\n> fundamentally different from data mining (DM) and knowledge discovery\n> (KD). These concepts are not of practical use because they neglect the\n> problems of \"data acquisition\" and its practice (332).\n\nIt is significant that Ohsumi excludes these new fields---or field,\nsince the two so frequently co-occur, along with the variant KDD,\n\"knowledge discovery in databases\"---from his definition of data\nscience, since many today would consider the two synonymous.\n\n### Data Mining and Knowledge Discovery\n\nThe paradox is instructive: the name \"data mining,\" as used here, makes\nits appearance in the late 1980s and early 1990s as a rubric that\nincluded a set of practices motivated by precisely the same conditions\nthat led the Tokyo school to propose the field of data science in the\nfirst place. Among these conditions was the relatively sudden appearance\nof vast amounts of data stored in databases---one of the fruits of\nclassical data science---owing to the rise of relational databases and\npersonal computing in the 1980s, and a suite of tools to work with data,\nfrom spreadsheets to programming languages to statistical software\npackages. Whereas many statisticians viewed these developments with\nalarm, being acutely aware of the epistemic disruptions they produced\nfor the received workflow of data analysis, the data mining community\nembraced them as an opportunity to convert data into value. Coming\nmainly from the field of computer science, data miners developed a set\nof methods that included the application of machine learning algorithms\nto the data found in databases in various contexts, from science to\nindustry (such as point-of-sale records generated as by-product of\ncomputerized cash registers and credit card use). The relationship\nbetween machine learning and data mining was also mutually\nbeneficial---data miners supplied machine learning with the large sets\nof data required for this class of algorithms to perform well. This\nrelationship was greatly reinforced with the rise and development of the\nWeb and social media platforms, which generated enormous amounts of\nbehavioral data.\n\nAlthough the two fields---for simplicity, let's call them data analysis\nand data mining---were responding to the same conditions of data surplus\nand impedance, their philosophical orientations could not have been more\nopposed. This difference is clearest in their respective evaluations of\ndata *provenance*, the source and conditions under which data are\nproduced. For the data miner, data provenance is largely irrelevant to\nthe possibility of converting data into value. Data are data, regardless\nof how they are generated, and the same methods may be applied to them\nregardless of source, so long as their structure is understood (e.g.\ntime series). (Indeed, for the data miner data exists much as natural\nresources do, as a given part of the environment, which helps explain\nthe success of the metaphor of *mining* over competing variants, such as\n*harvesting*, which implies intentional creation.) For the data analyst,\nas Hayashi and Ohsumi took such pains to emphasize, provenance is, or\nshould be, everything, echoing the statistician's orthodox preference\nfor experimental over observational data.\n\nIn defining data science in opposition to data mining, Ohsumi explains:\n\n> Owing to the qualitative and quantitative changes in data \\[produced\n> by the conditions described above\\], it is, indeed, becoming\n> increasingly difficulty to grasp all aspects of a dataset in\n> explaining various phenomena. Therefore, new techniques, such as DM,\n> KD, complexity, and neural networks, are being proposed. However, the\n> potential of these methods to solve any of these problems is\n> questionable (332).\n\nOhsumi goes on to characterize the way data has changed by listing the\nnew kinds of data with which the statistician is confronted. These\ninclude prominently data sets found in databases as by-products of\nvarious processes, such as passive accumulation (e.g. from point-of-sale\ndevices), unstructured data (included in text fields), and aggregated\ndata generated \"spontaneously and accumulating automatically in the\nelectronic data collection environment\" (332-333). He explained his\nconcern with data mining:\n\n> When it comes to analyzing these datasets, people discuss DM and\n> related techniques. However, the important questions to answer are:\n> what dataset is necessary to explicate a certain phenomenon, why is it\n> necessary, how to design its acquisition, and how difficult the whole\n> process is. *This is more important than the dataset itself*. Books on\n> DM do contain terms such as \"data preparation\", \"getting the data\",\n> \"sampling procedures\", and \"data auditing\", but there is an assumption\n> that the dataset is given and the procedure may start with analysis.\n> Fiddling with a dataset once it is collected is merely a\n> self-contained play of data handling [@ohsumi2000: 333; emphasis\n> added].\n\nAlthough his evaluation of data mining seems to be woefully off base---a\ngreat deal of Google's success, to take one example, was founded on\ntheir embrace of data mining at the time of Ohsumi's essay---in fact his\nconcern is not with the success of predictive analytics *per se*, but\nwith solving what he considered to be the central problem of data\nscience, that of understanding how data are generated in the first\nplace. Given some of the issues that classifiers have encountered with\nrespect to racial bias, for example, he cannot be said to have been\nwrong.\n\n### 1997: Statistical Data Science 2\n\nIn the late 1990s and early 2000s, a series of papers and presentations\nby academic statisticians in the US echoed the theme of malaise\nexpressed by the Tokyo school: the field of statistics was suffering\nfrom an image problem and needed to redefine itself in order to meet the\nchallenges of a variety of existential threats. These threats included\nthe rise of computational methods and large amounts of data, the\nemergence of non-traditional predictive methods and areas of research,\nsuch as data mining, that were taking the limelight from statistics, and\nan unflattering public image. Interestingly, given the lack of reference\nto the Tokyo school in these sources, many of the proposed responses\nincluded expanding the scope of statistics to encompass these new\nmethods and to rebrand the field as \"data science.\" Frequently\nassociated with this suggestion was a concern for updating university\ncurricula for teaching statistics and, apparently for the first time,\nthe creation of a new kind of statistician, the \"data\nscientist\"---recalling the mythical figure of the \"whole statistician\"\ndiscussed by Tukey in the 1970s. In these exhortations to the community\nof statisticians, the data scientist emerged as the \"new man\" of a\nreborn statistical science, one that who would overcome the field's\ncrisis of recognition.\n\nThe first of these exhortations appears to have come from Jon R.\nKettenring in his Presidential Address to the American Statistical\nAssociation on 12 August 1997, where he expressed concern for image of\nstatistics:\n\n> Looking ahead, image reconstruction must be one of our top priorities.\n> It must be understood that *statistics is the data science of the 21st\n> century*---essential for the proper running of government, central to\n> decision making in industry, and a core component of modern curricula\n> at all levels of education. I would like to see ASA make image\n> reconstruction a part of its strategic plan. And I suspect we may need\n> some professional help if we are to succeed\n> [@89618ac5-1e4e-3cce-a5de-eb7b926f27c9: 1230, emphasis added].\n\nIn this talk, Kettenring clearly expressed the ambivalence of the\nstatistics community toward the rise of computational methods that we\nsaw in the Tokyo school. On one hand, computer science was welcomed and\nit's contributions were viewed as opportunities:\n\n> I believe the time has come for us to acknowledge that computer\n> science needs to take its place alongside mathematics (and\n> probability) as fundamental linch pins of statistics and as\n> disciplines that undergird our research and instruction. Examples of\n> relevant topics in computer (and computing) science include databases\n> and database management, algorithm design, computational statistics,\n> artificial intelligence and machine learning\n> [@89618ac5-1e4e-3cce-a5de-eb7b926f27c9: 1232].\n\nOn the other hand, data mining---the most notable development coming\nfrom the computational field---was excluded from this vision. Not only\nwas it absent from the list of relevant topics above, it was singled out\nfor criticism, echoing the stance of the Tokyo school. In highlighting\nsoftware development and data mining as \"two opportunities that sit at\nthe intersection of computer science and statistics,\" Kettenring wrote:\n\n> The second area is the current hot topic of data mining, which\n> statisticians might reasonably think of as data analysis of very large\n> databases. In fact, if you dig down and look at what is involved in\n> data mining, you will find a variety of statistical components, such\n> as statistical graphics and cluster analysis. Moreover, there is a\n> great opportunity to bring a variety of statistical concepts to\n> bear---modeling, sampling, robust estimation, outlier detection,\n> dimensionality reduction, etc. Nevertheless, there are new\n> opportunities as well, and we would be wise to pay very close\n> attention and to become seriously involved with these developments.\n>\n> In fact, if we don't, there is risk that we will be blown away by the\n> momentum that is flowing in this direction. As Jerry Friedman pointed\n> out in his keynote address at Interface '97, we are no longer the only\n> game in town. Many other data oriented sciences are competing with us\n> for customers and students.\n>\n> Also it should not go unnoticed-speaking of image reconstruction!-that\n> the very term, data mining, has captured the fancy of many people,\n> especially in the business community. It is grabbing headlines that\n> statisticians would kill for. The image of data mining is that\n> something powerful is going on there. The reality? Well that may be\n> rather different. It may even turn out that the phrase of the day in\n> the 21st century is\n>\n> > lies, damned lies, and data mining.\n>\n> But for now I believe we should take advantage of the momentum before\n> it fades into another missed opportunity for statistics\n> [@89618ac5-1e4e-3cce-a5de-eb7b926f27c9: 1232].\n\nAs an aside, it is worth noting that Friedman in the keynote referenced\nabove, expressed the same ambivalence toward data mining. It is at once\nlauded as \"having a major impact in business, industry, and science\"\naffording \"enormous research opportunities for new methodological\ndevelopments\" and derided as a \"device to sell computer hardware and\nsoftware\" [@friedman1997].\n\nKettenring's message was echoed three months later by the academic\nstatistician C. F. Jeff Wu in a lecture delivered at the University of\nMichigan entitled \"Statistics = Data Science?\" [@wu1997]. Note that\nalthough Wu was not the first to suggest that statistics be renamed to,\nand redefined as, data science, he is often regarded as the first in the\nUS to do so [@donoho2017]. Regarding image, Wu pointed out that\nstatisticians were perceived as either accountants or involved with\nsimple descriptive statistics---and prone to lying with these\nstatistics, as the saying goes---when in fact their work comprised\neverything from data collection to modeling and analysis to solving\nproblems and making decisions. As a remedy, he implored his colleagues\nto \"think big\" and embrace the changes and challenges that we have seen\nalready---the rise of large and complex data sets, the use of neural\nnetworks and data mining methods, and the emergence of new fields such\nas computer vision. In addition to suggesting a name change for the\nfield, he appears to have been the first to suggest a name change of the\nrole of statistician to data scientist, along with a college curriculum\nto that would embrace all phases of data science and be profoundly\ninterdisciplinary.\n\nWu's proposal is stronger than Kettenring's. Kettenring, whose language\nsuggests that he was aware of the prior existence of data science as a\nfield, believed that statistics should embrace and encompass data\nscience as the rightful heir to its fruits and labors. In contrast, Wu\nasserted that statistics should expand its scope and rename itself \"data\nscience,\" because it \"is likely the remaining good name reserved for us\"\n[@wu1997a: slide 12]. In both cases, however, the usage of the term data\nscience included much of computer science, which is consistent with the\nclassical definition that developed in the 1960s and '70s.\n\nPractical plans for revamped curricula to train this new kind of\nstatistician---the data scientist---appear after these appeals. The most\nwell-known is found in Cleveland's essay, \"Data Science: An Action Plan\nfor Expanding the Technical Areas of the Field of Statistics\"\n[@cleveland2001], even though he used the term \"data analyst\" as his\ntarget student. Consistent with previous definitions of data science as\nstatistics augmented by computational methods and tools, he proposed a\ncurriculum comprising six areas, along with percentages denoting the\namount of time and resources that should be devoted to each:\nMultidisciplinary Investigations (25%), Models and Method for Data\n(20%), Computing with Data (15%), Pedagogy (15%), Tool Evaluation (5%),\nand Theory (20%). This distribution is more or less consistent with the\ndefinitions we have seen proposed by other statisticians, including the\nTokyo school. As a measure of how radical this suggestion was, consider\nDonoho's remarks, made over a decade and a half later:\n\n> Several academic statistics departments that I know well could, at the\n> time of Cleveland's publication, fit 100% of their activity into the\n> 20% Cleveland allowed for theory. Cleveland's article was republished\n> in 2014. I cannot think of an academic department that devotes today\n> 15% of its effort on pedagogy, or 15% on computing with data. I can\n> think of several academic statistics departments that continue to fit\n> essentially all their activity into the last category, theory\n> [@donoho2017: 750].\n\nRadical as it may have appeared, the curriculum was fairly conservative.\nThe area of \"models and methods,\" for example, focused exclusively on\nstatistical data models, as opposed to algorithmic ones (to use\nBreiman's terms, discussed below), while the \"computing with data\" area\nfocused narrowly on the infrastructure to support these models.\nCleveland's bias toward traditional statistical modeling is made clear\nin his explanation of it:\n\n> The data analyst faces two critical tasks that employ statistical\n> models and methods: (1) specification---the building of a model for\n> the data; (2) estimation and distribution---formal,\n> mathematical-probabilistic inferences, conditional on the model, in\n> which quantities of a model are estimated, and uncertainty is\n> characterized by probability distributions [@cleveland2001: 22].\n\nThat the one is subordinate to the other is evident in Cleveland's\nremark: \"A collection of models and methods for data analysis will be\nused only if the collection is implemented in a computing environment\nthat makes the models and methods sufficiently efficient to use\" (23).\nHe did make a passing reference to algorithmic models, but his example\ncame from their use to support stochastic modeling:\n\n> Historically, the field of data science has concerned itself only with\n> one corner of this large domain \\[i.e. computing with\n> data\\]---computational algorithms. Here, even though effort has been\n> small compared with that for other areas, the impact has been large.\n> One example is Bayesian methods, where breakthroughs in computational\n> methods took a promising intellectual current and turned it into a\n> highly practical, widely used general approach to statistical\n> inference (23).\n\nIf it is not made clear from this passage that he did not have the wider\nfield of data mining and knowledge discovery in mind, the following\npassage does:\n\n> Computer scientists, waking up to the value of the information stored,\n> processed, and transmitted by today's computing environments, have\n> attempted to fill the void. Once current of work is data mining. *But\n> the benefit to the data analyst has been limited, because knowledge\n> among computer scientists about how to think of and approach the\n> analysis of data is limited*, just as the knowledge of computing\n> environments by statisticians is limited (23; emphasis added).\n\nSo, Cleveland continued the practice of the Tokyo school to put at arms\nlength the contributions of data miners, for their lack of training in\ntraditional statistics or their lack of attention to data design, and to\nconfine the role of computational expertise to knowledge of\n\"environments.\"\n\n::: bourdieu\nRegarding the argument being made here, that the term \"data science\" has\nbeen in continuous circulation since the 1960s, and not independently\ncoined in various contexts, Cleveland's remarks, similar to those of\nKettenring, indicate that the term was already known to statisticians,\neven as they sought to appropriate it for their own purposes. The\nsentence---\"Historically, the field of data science has concerned itself\nonly with one corner of this large domain ...\"---indicates awareness of\nprior usage, as well as a definition that aligns with what we have\ncalled classical data science. In any case, as we have seen, CODATA,\nrepresenting classical data science, began publishing the *Data Science\nJournal* in 2001, the time of Cleveland's proposal.\n:::\n\nThe task of educating data scientists was also addressed at this time at\na workshop sponsored by the American Statistical Association in 2000 on\nthe topic of undergraduate education in statistics. In a report of the\nproceedings published in the *American Statistician*, the following\nunderstanding of data science was expressed:\n\n> ... what is needed is a broader conception of statistics, a conception\n> that includes data management and computer skills that assist in\n> managing, exploring, and describing data. The terms \"data scientist\"\n> or \"data specialist\" were suggested as perhaps more accurate\n> descriptions of what should be desired in an undergraduate statistics\n> degree. Data specialists would be concerned with the \"front end\" of a\n> data analysis project: designing and managing data collection,\n> designing and managing databases, manipulating and transforming data,\n> performing exploratory and \"basic\" analysis [@higgins1999]. Data\n> scientists (or specialists) a might share some course work with\n> computer science majors, but where a computer scientist studies\n> compilers and assembly language, a data scientist studies data\n> analysis and statistics [@bryce2001: 12; citation in original].\n\nThe reference to Higgins is from a paper where he asserted the need for\nstatisticians to pay more attention to \"the non-mathematical part of\nstatistics,\" so that undergraduate programs may respond to the\n\"explosion in the amount of data available to society\" [@higgins1999:\n1]. In this area he included \"designing scientific studies in a\nteam-oriented environment, ensuring protocol compliance, ensuring data\nquality, managing the storage/transmission/retrieval of data, and\nproviding descriptive and graphical analyses of data\" (1). Here, again,\nwe see a definition of data science as an improved version of\nstatistics, in response to the persistent condition of data impedance,\nthat would include data management and computing skills (and data\ndesign)---but not the methods of data mining. Consistent with the\nimplied structural relationship between statistics and data science,\ndata science was sometimes described as a part of statistics. Tellingly,\nboth Bryce, et al., and Higgins equivocated on the use of data\nscientist, and suggested \"data specialist\" as an alternate name, perhaps\nso as not to overshadow the role of the data analyst. In any case, the\nchoice of term was motivated by marketing; as Higgins wrote:\n\n> Guttman expressed the opinion that the term statistics carries such a\n> negative connotation that it might be wise to rename our departments\n> something like \"Department of Data Science\" or \"Department of\n> Information and Data Science.\" In this vein, I have suggested the term\n> \"data specialist\" [@higgins1999].[^ds-from-1963-to-2012-14]\n\n[^ds-from-1963-to-2012-14]: Higgins here referred to a quote from\n    Guttman found in a paper by Kettenring (Kettenring 1997a).\n\n## The 2000s\n\n### Breiman: A Prophet in the Wilderness\n\nPerhaps the most eloquent and authoritative account of the difference\nbetween what we are calling data analysis and data mining is found in\nLeo Breiman's contemporary essay on an analogous pairing, what he\ncalled, echoing C. P. Snow, the \"two cultures\" of statistical modeling\n[@breiman2001]. In brief, one culture seeks to represent causality---the\nblack box of nature that generates the empirical data with which\nstatistics begins---by means of probabilistic or stochastic data models.\nThe parameters, random variables, and relationships that compose these\nmodels are imagined to correspond to things in the world, at least in\nprinciple. Data are used to estimate the parameters of these models.\nThis is the \"data modeling culture,\" associated with traditional\nstatistics and data analysis. Breiman guessed this culture comprised 98%\nof all statisticians, broadly conceived. The other culture bypasses\nattempts to directly model the contents of the black box and instead\nfocuses on accounting for the data by means of goal-oriented algorithms,\nregardless of the correspondence of these to the world. This is the\n\"algorithmic modeling culture,\" associated with computer science,\nmachine learning, and, we might add, data mining. Breiman described the\ngrowth of this culture as \"rapid\" (beginning circa 1985) and\ncharacterized its results as \"startling\" [@breiman2001: 200].\n\nAs Ohsumi wrote, for one culture the data models are more important than\nthe data, and not all data are suitable to supporting the development of\ngood data models. Hence the emphasis on design for data---the most\nimportant phase of data science is in the careful production of data.\nFor the other, data are both abundant and intrinsically valuable, and to\na great extent have the power to account for themselves. Whereas the\nformer is highly selective about the data it employs, and views with\ngreat suspicion---as we have seen---new forms of data coming from\ndatabases in a variety of formats, the latter embrace these data, and\nare not daunted by their size and complexity. On the contrary, these\nqualities are essential to the methods applied.\n\nThe point of Breiman's essay was to convince the 98% that their\ncommitment to correspondence models had led to \"irrelevant theory and\nquestionable scientific conclusions\" about underlying mechanisms.\nPerhaps more important, he argued that their priestly avoidance of\nimpure algorithmic methods and data \"not suitable for analysis by data\nmodels\" (i.e. the accidental data found in databases, as opposed to data\ncreated by design) had prevented \"statisticians from working on exciting\nnew problems\" (199--200). The canary had forgotten to sing, but for\nreasons precisely opposite to that claimed by the Tokyo school, whom\nBreiman may have admonished for an excessive concern for the conditions\nof acquisition.\n\n::: bourdieu\nOne way to account for the difference between the two cultures is to\ncompare their institutional settings. The data modeling culture is\nclosely aligned with the project of academic science and the search for\nintelligible models of nature, whereas the latter are more associated\nwith business needs, the pragmatic decision-making requirements of those\nclients who own the databases in the first place. This difference is\nreflected in Breiman's own biography, which is that of a liminal figure\nin this binary. He spent significant amounts of time as both an\n\"academic probabilist\" and as a free-lance consultant to industry and\ngovernment, where he \"became a member of the small second culture.\"\nIndeed, in the mid-1970s Breiman worked for Data Sciences Division of\nTechnology Services Corporation [@breiman1976]. These different value\norientations---deriving from the purpose for which one works with data\nin the first place---are reflected in their attitudes toward data and\nmodels. For one group, models are the capital on which one builds a\ncareer and a name. One wins a Nobel Prize for a successful model of the\nworld, not for collecting the data upon which it was built, which are\noften forgotten and poorly documented. In business, however, models come\nand go, but the data constitute an irreplaceable form of capital, often\ntaking years to accumulate and jealously guarded. Thus, for one group,\nmodels precede data; for the other, data precedes models. We might\ncharacterize the former as *essentialist* and the latter as\n*existentialist*, given the analogy that data : models :: existence :\nessence.\n:::\n\n### Data Mining Considered Harmful\n\nBreiman's essay marks a significant shift in the history of data\nscience, a reversal in how data are regarded in relation to models.\nConsider that the phrase \"data mining\" itself, which was actually used\nby econometric statisticians to refer to the frowned upon practice of\nfishing for models in the data, of letting data specify models, a usage\ndating back to 1966 and at least up to 1995 [@lovell1983; @ando1966;\n@hendry1995: 544]. In his review of the concept in 1983, Lovell's\nremarks make it clear that the two usages are not entirely unrelated:\n\n> The development of data banks \\... has increased tremendously the\n> efficiency with which the investigator marshals evidence. The art of\n> fishing over alternative models has been partially automated with\n> stepwise regression programs. While such advances have made it easier\n> to find high $\\overline{R}^ 2$s and \"significant\" *t*-coefficients, it\n> is by no means obvious that reductions in the costs of data mining\n> have been matched by a proportional increase in our knowledge of how\n> the economy actually works [@lovell1983: 1].\n>\n> When a data miner uncovers *t*-statistics that appear significant at\n> the 0.05 level by running a large number of alternative regressions on\n> the same body of data, the probability of a Type I error of rejecting\n> the null hypothesis when it is true is much greater than the claimed\n> 5% (1).\n>\n> It is ironic that the data mining procedure that is most likely to\n> produce regression results that appear impressive in terms of the\n> customary criteria is also likely to be the most misleading in terms\n> of what it asserts about the underlying process generating the data\n> under study (10).\n\nThe fact that the same phrase, with a common referent but opposite\nsentiments, would be used contemporaneously is an indication of the\nsocial distance between the two cultures. But also, we can see that the\napproach Breiman proposed was exactly what was criticized by these\nstatisticians: among the perceptions, or principles, he acquired as a\nconsultant to work successfully with data, he specified the \"\\[s\\]earch\nfor a model that gives a good solution, either algorithmic or data\"\n(201), a definition of data mining that would fit among those quoted,\nwith wry humor, by Lovell. In fact, the meaning of data mining, even\namong statisticians, changes during this period, going from a bad habit\nto a hot new area of research. Its negative evaluation by some, however,\nhas persisted.\n\n::: bourdieu\nIn defense of data miners against the criticisms of econometric\nstatisticians and those of the Tokyo school, their focus on already\ncollected data reflects Naur's view that data science should focus on\nrepresentation and transformation, and not on establishment and domain\nknowledge---precisely the areas on which the Tokyo school focused. But\nmore important, data miners had discovered something that data analysis\nhad not, at least not as a shared perspective: data in fact do have a\ncertain autonomy with respect to their provenance, and a variety of\nmethods, including many from statistics, were revealing an entirely new\nand quite radical paradigm of science---one without need of \"theory\"\n[@anderson2008]. \"Self-contained play\" actually pays off. In a certain\nsense, data miners were carrying out a principle asserted by Claude\nShannon in his groundbreaking essay on information theory---that the\n\"semantic aspects of communication are irrelevant to the engineering\nproblem\" [@shannon1948: 5]. The engineering problem in this case being\nthe ability to discover significant patterns among features and to make\npredictions, and the semantics being the relationship between phenomena\nand data.\n:::\n\nAt the most general level, the epistemological orientations of the two\ncultures can be described by reference to how each understands the\nproper relationship between data and models on the one hand and\nmotivating questions on the other. For the traditional data analyst, one\nacquires data and develops models in order to answer scientific\nquestions. These derive from established fields ranging across the\nnatural, life, and social sciences, from which there is no shortage of\ncompelling problems to solve. For the data miner, the relationship is\nreversed: the presence of abundant data, found in databases, creates a\nneed to find value in them, a vacuum to fill. Although, as we have seen,\nthe field is sometimes called knowledge discovery, it might better have\nbeen called *question* discovery. Consider this sentence, drawn from an\nearly essay on KDD: \"American Airlines is looking for patterns in its\nfrequent flyer databases\" [@piatetsky-shapiro1991]. This is not\nsomething a data analyst would utter publicly.\n\nIt is hard to overestimate the width of the gap between these two\nfields. To this day, statisticians, who view themselves as the\ninheritors and guardians of the scientific method, regard the\nunidirectional relationship between understanding why and how one\ncollects data, and the collected data themselves, nearly as strongly as\ngeneticists regard the relationship between genotype and phenotype---the\narrow of information moves in one direction. Epigenetics\nnotwithstanding, violation of this dogma is tantamount to heresy. The\ndata miner has no such concern; data are data and data have value. The\ntrick is to discover that value before anyone else does. This is not to\nsay that data miners do not have questions in hand before working with\ndata. Often clients have very specific questions, and existing databases\nare found that more or less match the requirements of the question.\nIndeed, in defending himself against Cox's charge of putting data before\nquestions, Breiman wrote:\n\n> I have never worked on project that has started with \"Here is a lot of\n> data; let's look at it and see if we can get some ideas on how we can\n> use it.\" The data has been put together and analyzed starting with an\n> objective (226).\n\nThere is a difference between a general objective and a specific\nquestion. In these cases, the data miner is much more likely to work\nhappily with these data and not wait for experimental data to be\nproduced. If she does not succeed, she is as likely to blame her methods\nmore than the data themselves. It is telling that in recounting his\nfailure to come up with a predictive model of smog formation in Los\nAngeles, Breiman wished he had had \"the tools available today,\" not\nbetter data (201).\n\n::: comment\n*Connect Breiman to 1990s movements. Describes the structural\ncontradiction that gave rise tod the movements to the malaise and the\ndesire to rebirth statistics.*\n\nIn his remarks to the commentators on his essay, among whom were Cox and\nParzen, Breiman lamented: \"Many of the best statisticians I have talked\nto over the past years have serious concerns about the viability of\nstatistics as a field\" (231).\n:::\n\n### 2005: Data Science in the Sciences\n\nAs some members of the statistics community presented plans to\nincorporate data science into their field, the terms \"data science\" and\n\"data scientist\" nevertheless continued to be used in the classical\nsense of the science of data in the service of science. Indeed, by 2005,\nthe role of data scientist had become sufficiently developed within the\nscientific community that it appeared as a central element in a report\nfrom the US National Science Foundation (NSF), \"Long-Lived Digital Data\nCollections: Enabling Research and Education in the 21st Century\"\n[@simberloff2005]. The report defines the role in specific terms:\n\n> DATA SCIENTISTS\n>\n> The interests of data scientists---the information and computer\n> scientists, database and software engineers and programmers,\n> disciplinary experts, curators and expert annotators, librarians,\n> archivists, and others, who are crucial to the successful management\n> of a digital data collection---lie in having their creativity and\n> intellectual contributions fully recognized. In pursuing these\n> interests, they have the responsibility to:\n>\n> -   conduct creative inquiry and analysis;\n>\n> -   enhance through consultation, collaboration, and coordination the\n>     ability of others to conduct research and education using digital\n>     data collections;\n>\n> -   be at the forefront in developing innovative concepts in database\n>     technology and information sciences, *including methods for data\n>     visualization and information discovery*, and applying these in\n>     the fields of science and education relevant to the collection;\n>\n> -   implement best practices and technology;\n>\n> -   serve as a mentor to beginning or transitioning investigators,\n>     students and others interested in pursuing data science; and\n>     design and implement education and outreach programs that make the\n>     benefits of data collections and digital information science\n>     available to the broadest possible range of researchers,\n>     educators, students, and the general public.\n>\n> Almost all long-lived digital data collections contain data that are\n> materially different: text, electro-optical images, x-ray images,\n> spatial coordinates, topographical maps, acoustic returns, and\n> hyper-spectral images. In some cases, it has been the data scientist\n> who has determined how to register one category of representation\n> against another and how to cross-check and combine the metadata to\n> ensure accurate feature registration. Likewise, there have been cases\n> of data scientists developing a model that permits representation of\n> behavior at very different levels to be integrated. *Research insights\n> can arise from the deep understanding of the data scientist of the\n> fundamental nature of the representation. Such insights complement the\n> insights of the domain expert. As a result, data scientists sometimes\n> are primary contributors to research progress.* Their contribution\n> should be documented and recognized. One means for recognition is\n> through publication, i.e., refereed papers in which they are among the\n> leading authors [@simberloff2005: 26; emphases added].\n\nThis account of the role of data scientist demonstrates both the\ncurrency of the term and its adherence to the classical definition.\nAgain, this usage stood in contrast to that developed in the statistics\ncommunity for its emphasis on the creative role of data curation and\nrepresentation and its sympathetic view toward knowledge discovery. It\nis also worth noting the normative intent of the definition---the report\ndescribed the role of data scientist as both heterogeneous---comprising\na wide array of knowledge workers from computer scientists to\nlibrarians---and undervalued. The report sought to correct this\ncondition. As evidence for its influence, consider that Purdue\nUniversity's Distributed Data Curation Center (D2C2), founded in 2007 as\n\"a research center that would connect domain scientists, librarians,\narchivists, computer scientists, and information technologists\" to\naddress \"the need by researchers for help in discovering, managing,\nsharing, and archiving their research data,\" included \"a full-time Data\nResearch Scientist, a position based on the data scientist role\" as\ndescribed in the report [@witt2008: 199].\n\nThe NSF report drew on the established usage of the term in the\nscientific community. During this period there appeared numerous\ninstances of the term \"data scientist\" in popular media that are\nconsistent with the classical definition of data science. For example,\nin 2008 *The Times* of London published a piece that quoted \"Nathan\nCunningham, 36, data scientist, British Antarctic Survey\":\n\n> When I am on the ship I am part of a team of scientists collecting\n> data about everything from the biomass in the ocean to the weather\n> patterns. ... Our monitoring equipment is always on and sends us 180\n> pieces of information every second. *My role is to make sure that each\n> person can find the exact data that they want among all this, so I\n> write programs to help them to do this*. Another one of my field\n> responsibilities is getting the information that we collect back to\n> Cambridge via satellite link so that other researchers can use the\n> data [@chynoweth2008; emphasis added].\n\nOther stories about data scientists were reported in news media touting\nthe work of local universities, such as at Brigham Young University and\nRensselaer Polytechnic Institute (Harmon 2007; Targeted News Service\n2008). The *New Scientist* posted job ads for data scientists as far\nback as 1992 [@newscie1992; @newscie1995a; @newscie1996; @newscie1999;\n@newscie2001]. In some cases, the term was prefixed, as in \"Clinical\nData Scientist,\" \"Marine Data Scientist,\" and \"Senior Data Scientist,\"\nbut in others it was not.\n\nAlongside but contrary to plans for data science curricula from the\nstatisticians' perspective, computer scientists and scientists in\ndisciplines that had long been engaged with data impedance, such as\nphysics and astronomy, began to outline requirements for data science to\nbecome a mature field. In \"Data Science as an Academic Discipline,\"\npublished in CODATA's *Data Science Journal*, Irish computer scientist\nF. Jack Smith (OBE) argued for data science to develop its own\npeer-reviewed body of knowledge, in the form of refereed journals and\ntextbooks, on the premise that \"\\[o\\]nce a body of literature is in\nplace, academic courses can begin at universities\" [@smith2006: 164].\nConsistent with the journal's source, Smith's definition of data science\nwas different to that proposed by Wu and Cleveland. The following\nhistorical perspective makes this clear:\n\n> To be taken seriously, any discipline needs to have endured over time.\n> Unlike computers, scientific data has a long history. Without\n> astronomic data, Newton would not have discovered gravitation. Without\n> data on materials, the Titanic would not have been built, and with\n> good data on the location of icebergs, it might not have sunk! Data\n> then consisted of tables of facts and quantities found in textbooks\n> and journals, but data science did not yet exist. *Then computers and\n> mass storage devices became available, and the first databases were\n> designed holding scientific data. Data science was born soon\n> afterwards, about 1966, when a few far seeing pioneers formed CODATA*.\n>\n> Data science has developed since to include the study of the capture\n> of data, their analysis, metadata, fast retrieval, archiving,\n> exchange, *mining to find unexpected knowledge and data\n> relationships*, visualization in two and three dimensions including\n> movement, and management. Also included are intellectual property\n> rights and other legal issues*.*\n>\n> Data science, however, has become more than this, something that the\n> pioneers who started CODATA could not have foreseen; data has ceased\n> being exclusively held in large databases on centrally located main\n> frames but has become scattered across an internet, instantly\n> accessible by personal computers that can themselves store gigabytes\n> of data. *Therefore, the nature and scope of much scientific and\n> engineering data and, in consequence, of much scientific research has\n> changed.* Measurement technologies have also improved in quality and\n> quantity with measurement times reduced by orders of magnitude.\n> Virtually every area of science, astronomy, chemistry, geoscience,\n> physics, biology, and engineering is also becoming based on *models\n> dependent on large bodies of data, often terabytes, held in large\n> scientific data systems* (163; emphases added).\n\nThis view, close to that espoused here, locates data science in the\nhistorically specific emergence of networked, computational\ndatabases---what has been called the datasphere [@garfinkel2000;\n@alvarado2017]. This emphasis on the dependence of models on this\ninfrastructure represents what seems to be a distinct view to that of\nthe statistician, who tends to regard these developments as exogenous to\nher engagement with data. Put another way, for the statistician, the\nhistorical shift from data to databases---from print to digital modes of\ncommunication---is often represented as a difference in degree, but for\nthe scientist, who produces and lives among these data, it is a\ndifference in kind. This difference in perspective was not without\nepistemic consequences. For one, Smith's definition clearly included\ndata mining. For another, just as data mining had been excluded from the\nstatistician's definition of data science, so too was a concern for\ndatabases excluded from what was considered worthwhile scientific work:\n\n> I recall being a proud young academic about 1970; I had just received\n> a research grant to build and study a scientific database, and I had\n> joined CODATA. I was looking forward to the future in this new\n> exciting discipline when the head of my department, an internationally\n> known professor, advised me that data was \"a low level activity\" not\n> suitable for an academic. I recall my dismay. What can we do to ensure\n> that this does not happen again and that data science is universally\n> recognized as a worthwhile academic activity? Incidentally, I did not\n> take that advice, or I would not be writing this essay, but moved into\n> computer science. I will use my experience to draw comparisons between\n> the problems computer science had to become academically recognized\n> and those faced by data science [@smith2006:\n> 163].[^ds-from-1963-to-2012-15]\n\n[^ds-from-1963-to-2012-15]: Based on the affiliations cited in his three\n    publications between 1960 and 1969, the setting for Smith's story\n    was the School of Physics and Applied Mathematics at the Queen's\n    University of Belfast in Northern Ireland.\n\nFurther evidence for the divergent conceptions of data science held by\nstatisticians and scientists during this period appears in an ambitious\nposition paper prepared for the 2010 Astronomy and Astrophysics Decadal\nSurvey, written to \"address the impact of the emerging discipline of\ndata science on astronomy education\" [@borne2009]. Building on Smith's\nconception of both science and data science, the report cited the usual\nconcerns with data impedance---the gap between information and data on\nthe one hand and knowledge and understanding on the other, produced by\n\"information explosion\" and \"exponential data deluge.\" As a response,\nthe authors proposed to redefine science as fundamentally data-driven\nand dependent upon computational technologies. Indeed, in their\nfour-part model, data were depicted as central, as the fourth node\nwithin a triangle consisting of \"Sensor,\" \"HPC,\" and \"Model.\" The result\nwas a conception of science in which data science would participate as a\nfirst-class member:\n\n> The emerging confluence of new technologies and approaches to science\n> has produced a new Data-Sensor-Computing-Model synergism. This has\n> been driven by numerous developments, including the information\n> explosion, the development of dynamic intelligent sensor networks\n> \\..., the acceleration in high performance computing (HPC) power, and\n> advances in algorithms, models, and theories. *Among these, the most\n> extreme is the growth in new data*. The acquisition of data in all\n> scientific disciplines is rapidly accelerating and causing a nearly\n> insurmountable data avalanche \\[3 [@bell2007]\\]. Computing power\n> doubles every 18 months (Moore's Law), corresponding to a factor of\n> 100 in ten years. The I/O bandwidth (into and out of our systems,\n> including data systems) increases by 10% each year---a factor 3 in ten\n> years. By comparison, data volumes appear to double every year (a\n> factor of 1,000 in ten years). Consequently, as growth in data volume\n> accelerates, especially in the natural sciences (where funding\n> certainly does not grow commensurate with data volumes), we will fall\n> further and further behind in our ability to access, analyze,\n> assimilate, and assemble knowledge from our data collections---unless\n> we develop and apply increasingly more powerful algorithms,\n> methodologies, and approaches. *This requires a new generation of\n> scientists and technologists trained in the discipline of data\n> science* \\[4 [@shapiro2006]\\] (1--2; emphases and citations added).\n\nThe inclusion of data mining in this conception is clear:\n\n> We see the data flood in all sciences (e.g., numerical simulations,\n> high-energy physics, bioinformatics, geosciences, climate monitoring\n> and modeling) and outside of the sciences (e.g., banking, healthcare,\n> homeland security, drug discovery, medical research, retail marketing,\n> e-mail). *The application of data mining, knowledge discovery, and\n> e-discovery tools to these growing data repositories is essential* to\n> the success of our social, financial, medical, government, and\n> scientific enterprises. (2; emphasis added)\n\nAlthough Cleveland's action plan was cited in this report, as evidence\nthat \"data science is becoming a recognized academic discipline\" (3), it\nis clear his definition of data science was not adopted. Instead, a\nconception of data science that included data mining and which would\nplay a central role in the scientific enterprise was more reflective of\nthe view expressed in Microsoft's contemporary and influential\npublication, *The Fourth Paradigm: Data-Intensive Scientific Discovery\n[@hey2009]*. Although the various authors did not use the term \"data\nscience\" at all, the role played by data, data technologies, and\nspecifically data mining, were highlighted throughout. To anticipate\nwhat follows, the fourth paradigm concept would later become one of the\ndominant, competing definitions of data science once the term is\npopularized after 2008.\n\nIf Microsoft's report did not use the term, other organizations cited\nwithin the report did. For example, what was then known as the Joint\nInformation Systems Committee (JISC), established in the UK in 1993 to\nprovide guidance to networking and information services to the entire\nkingdom's higher education sector, sponsored a report \"to examine and\nmake recommendations on the role and career development of data\nscientists and the associated supply of specialist data curation skills\nto the research community\" [@swan2008: 1]. Aware of the semantic\nconfusion surrounding the term by this time, the report offered this\nhelpful clarification of roles:\n\n> The nomenclature that currently prevails is inexact and can lead to\n> misunderstanding about the different data-related roles that exist.\n> ... We distinguish four roles: data creator, data scientist, data\n> manager and data librarian. We define them in brief as follows:\n>\n> -   Data creator: researchers with domain expertise who produce data.\n>     These people may have a high level of expertise in handling,\n>     manipulating and using data\n>\n> -   Data scientist: people who work where the research is carried\n>     out---or, in the case of data centre personnel, in close\n>     collaboration with the creators of the data---and may be involved\n>     in creative enquiry and analysis, enabling others to work with\n>     digital data, and developments in data base technology\n>\n> -   Data manager: computer scientists, information technologists or\n>     information scientists and who take responsibility for computing\n>     facilities, storage, continuing access and preservation of data\n>\n> -   Data librarian: people originating from the library community,\n>     trained and specialising in the curation, preservation and\n>     archiving of data\n>\n> In practice, there is not yet an exact use of such terms in the data\n> community, and the demarcation between roles may be blurred. It will\n> take time for a clear terminology to become general currency.\n>\n> Data science is now a topic of attention internationally. In the USA,\n> Canada, Australia, the UK and Europe, developments are occurring. It\n> is notable that the vision in all these places is that data science\n> should be organised and developed on a national pattern rather than\n> relying on piecemeal approaches to the issues (1).\n\nThese definitions, which expand our scope to include the wider division\nof labor within which data work took place, are illuminating. They show\nthat even as late as 2008, at precisely the time when a new usage of\ndata scientist emerged from Silicon Valley, the role was still more\nclosely associated with the classical definition than with the\ndefinitions proposed by the Tokyo school, Wu, and Cleveland. Again, the\nsalient difference concerns the role of the data scientist (or\nspecialist) relative to the liminal site of data creation at the heart\nof empirical science: the distinguishing features of the definition\ngiven above are that the data scientist works in \"close collaboration\nwith the creators of the data,\" \"where the research is carried out,\" and\n\"may be involved in creative enquiry and analysis.\" Indeed, the two\nroles, of researcher and data scientist, may be combined in one person.\nWe may be sure that \"creative enquiry\" here refers to more than the kind\nof data modeling performed by Breiman's data modeling culture. To make\nthe separation between statistician and data scientist clearer, consider\nthe following remark, made in reference to one perspective on whether\ndata science should be taught at the undergraduate level: \"data skills\nshould be viewed as a fundamental part of the education of\nundergraduates in the same way as basic statistics, laboratory practices\nand methods of recording findings are\" (24).\n\nIt is worth noting the curious appearance of the term \"dataology\" as\nthis time, spelled differently than Naur's \"datology,\" in the work of\nZhu, et al. as a synonym for data science. Apparently unaware of Naur,\nthese authors proposed a new science of data in response to data\nimpedance (\"data explosion\") that would focus on what they termed \"data\nnature\":\n\n> The essence of computer applications is to store things in the real\n> world into computer systems in the form of data, i.e., *it is a\n> process of producing data*. Some data are the records related to\n> culture and society, and others are the descriptions of phenomena of\n> universe and life. The large scale of data is rapidly generated and\n> stored in computer systems, which is called *data explosion*. *Data\n> explosion* forms *data nature* in computer systems. To explore data\n> nature, new theories and methods are required. In this paper, we\n> present the concept of data nature and introduce the problems arising\n> from data nature, and then we define a new discipline named\n> *dataology* (also called *data science* or *science of data*), which\n> is an umbrella of theories, methods and technologies for studying data\n> nature. The research issues and framework of *dataology* are proposed\n> [@zhu2009: abstract; emphases in original].\n\nThis definition was consistent with the classical definition and indeed\nechoed the concerns of the US Department of Defense to define data\ndecades earlier, as a prerequisite to developing technologies to process\nand manage it. It is also worth noting the change in understanding of\ndata impedance at this juncture; whereas originally the focus was on the\noverproduction of data by sources ranging from scholarly communication\nto satellite signals, in relation to machinery to process it, by this\ntime it referred to vast amounts of data collected in databases---the\nmachinery developed to manage data. This parallels the shift in focus we\nsaw in the Tokyo school, from raw data to data in databases. As the\nlocus of impedance changed, so too did the focus of data science (in\nthis usage). For Zhu, et al., data nature referred explicitly to data in\ndatabases and computer systems, and their concern was to understand the\nrelationship between data nature and real nature. Again, this shift is\nconsistent with the classical definition as well as Naur's; the focus is\non the epistemological dimensions of data, data as a form of\nrepresentation, as found in computational machinery. In contrast to Nau,\nhowever, the relationship between data and the world is considered\ncentral. From this perspective, data mining is regarded as a kind of\ndata science:\n\n> The appearance of data mining technology ... means that people began\n> to study the laws aiming at data in computer systems. In the field of\n> Internet, more and more researches focus on network behavior, network\n> community, network search, and network culture. Because of the\n> accumulation of data, newly disciplines, such as bioinformatics and\n> brain informatics, are also typical dataology centric research areas.\n> For instance, DNA data in bioinformatics are the data that describe\n> natural structures of life, based on which we can study life using\n> computers (153).\n\nIn other words, not only is data mining consistent with data science in\nthis view, it is central to it. More recently, the authors situate this\ndefinition within the array of definitions that currently characterize\nthe ambiguous nature of the field and which motivate the current essay\n[@zhu2015]. Consistent with their focus on data as it exists in\ndatabases, the authors focus on the role of the Internet and social\nmedia in constituting the field of data science. This is a perspective\nwe will revisit.\n\nDuring the first two decades following Berners-Lee's invention of the\nWeb, the term data science emerged from the long tail of usage, where it\nhad resided essentially since Naur, to become the sign of new kind of\nstatistics. This new statistics would overcome the limitations of a\nfield that had lost its way amidst the rise of computational data\nprocessing technologies and of what would eventually be called \"big\ndata,\" a term that we may take to be a synonym for the condition of data\nimpedance associated with the use of the term data science since the\n1960s. Ironically, big data was the product of what we might call the\nfirst wave response to data impedance; database technologies were\ndeveloped to contain and manage the oft mentioned \"data deluge,\" and\nthese in turned produced another flood, of software and enormous caches\nof aggregated data. In addition, they produced a nemesis to\nstatistics---the field of data mining.\n\nYet throughout out this period, classical data science persists and\nparadoxically becomes stronger, perhaps in response to the use of the\nterm among statisticians. We see that even up to the eve of the next\nmilestone, data science was widely understood to refer to work\nassociated with data processing, the theory and practice associated with\ndata, especially in the context of scientific research data. This was\nthe understanding of data science implied by CODATA's journal. We also\nnote that the classical definition, when it was articulated, was\nconsistently inclusive of the work of data miners. For their part, these\nnew workers did not appear to need the term; the phrase \"knowledge\ndiscovery (in databases),\" referring to the framing context of activity,\nwas sufficient to capture their understanding of their work\n[@fayyad1996].\n\n::: comment\nMay want to change the following to say \"re-emerged\"; depends on\ndiscussion of the 1980s.\n:::\n\nNotably, during this period the term \"data scientist\" emerged as well,\nin both statistical and classical contexts. Its appearance reflected a\nconcern for data science as an emerging profession, complete with\neducational requirements. In the statistician's usage, this position was\nambivalently placed within the general division of labor, as either a\nsynthetic \"new man\" figure that would encompass data analysis, or else\nas a \"data specialist,\" an adjunct to the more primary work of the data\nanalyst. In any case, the appearance of this grammatical variant\nindicates a transformation in the social context of usage: data science\nhad moved from being an abstract concern to a widely distributed and\nembedded activity.\n\n### 2008: The Sexy Science\n\nAround 2008 a decisive shift in the meanings of \"data science\" and \"data\nscientist\" took place. After nearly a half century of development, in\nwhich two broad and consistent usages had emerged---the classical and\nthe statistical---the term was applied in a context that launched it\ninto the public eye and increased its circulation by orders of\nmagnitude.[^ds-from-1963-to-2012-16] This context was the social media\ncorporation of the Web 2.0 era, itself the inheritor of two crowning\nachievements of data processing engineering---the database and the\nInternet---catalyzed by Berners-Lee's invention of a global hypertext\nsystem. According to what is perhaps the most popular article on the\ntopic, *Harvard Business Review*'s \"Data Scientist: The Sexiest Job of\nthe 21^st^ Century,\" the term \"data scientist\" was \"coined in 2008 by\n\\... D.J. Patil, and Jeff Hammerbacher, then the respective leads of\ndata and analytics efforts at LinkedIn and Facebook\"\n[@davenport2012].[^ds-from-1963-to-2012-17] Although on its face this\nclaim is obviously false, it is apparently correct in having identified\nthe first usages of the term in this new context.\n\n[^ds-from-1963-to-2012-16]: According to the Google Books NGram Viewer,\n    using the English (2019) corpus with a smoothing factor of 3, the\n    corpus frequency of the bigram \"data scientist\" (case insensitive)\n    goes from 0.0000000613% in 2008 to 0.0000035018% in 2012 and\n    0.0000118327% in 2016. These are increases from 2008 of around 57\n    and 193 for 2012 and 2016 respectively. By comparison, frequency\n    actually *decreases* by .6 from 2000 (.0000000876%) to 2008,\n    although the difference here is probably not significant\n    statistically; the frequency is essentially flat. The trend is\n    similar for \"data science,\" with increases of 11 and 56 times from\n    2008 to 2012 and 2016 respectively.\n\n[^ds-from-1963-to-2012-17]: The title of this article was adapted from a\n    phrase used in 2008 by Hal Varian, chief economist at Google. In an\n    interview with McKinsey's James Manyika, Varian quipped: \"I keep\n    saying the sexy job in the next ten years will be statisticians\"\n    (McKinsey & Company 2009).\n\nConsistent with this claim, in 2009 Hammerbacher published an essay\nrecounting his experience as a data scientist at Facebook entitled\n\"Information Platforms and the Rise of the Data Scientist\" (Hammerbacher\n2009), where he explained the motivation for adopting the term:\n\n> At Facebook, we felt that traditional titles such as Business Analyst,\n> Statistician, Engineer, and Research Scientist didn't quite capture\n> what we were after for our team. The workload for the role was\n> diverse: on any given day, a team member could author a multistage\n> processing pipeline in Python, design a hypothesis test, perform a\n> regression analysis over data samples with R, design and implement an\n> algorithm for some data-intensive product or service in Hadoop, or\n> communicate the results of our analyses to other members of the\n> organization in a clear and concise fashion. To capture the skill set\n> required to perform this multitude of tasks, we created the role of\n> \"Data Scientist\" (84).\n\nAlthough the work in this description appears evenly divided among\nengineering and statistical tasks, Hammerbacher's narrative actually\nfocused entirely on efforts to manage the data impedance problem that\nsocial media company (and others like it) faced at the time he was hired\nin 2006, just after they opened their doors to others than college\nstudents. It is a story of how a small group within the company moved\naway from a MySQL data warehouse, which literally ceased to function\nunder the volume of the company's data, and eventually to a new platform\nbased on Hadoop and Hive, in order to perform the standard tasks of\nextracting, transforming, and loading data (ETL) and building an\ninformation retrieval platform for analysts in the company. In addition\nto their massive scale, these data were also textual and social in\nnature, putting them in the same category as the complex data types the\nAir Force faced years ago.\n\nSignificantly, Hammerbacher emphasized Facebook's adoption of Google's\nmachine learning based approach, captured in the phrase \"the\nunreasonable effectiveness of data\" and explained in an essay with that\ntitle [@halevy2009]. In this approach, the size of data is considered\nmore important than the sophistication of models---\"invariably, simple\nmodels and a lot of data trump more elaborate models based on less data\"\n(9; also quoted by Hammerbacher).[^ds-from-1963-to-2012-18] In essence,\nthen, the new role of data scientist at Facebook was close to that of\nthe data scientist for the British Antarctic Survey, i.e. the classical,\nnot the statistical definition, with the added focus on machine\nlearning. Indeed, Hammerbacher appears to have recognized the provenance\nof the term:\n\n[^ds-from-1963-to-2012-18]: By \"simple,\" the authors meant few\n    assumptions about the nature of the data, such as are required by\n    data models that posit parametric distributions or causal relations\n    among features. The usage is ironic, since one of the differences\n    between the inferential models preferred by traditional\n    statisticians and predictive models is that the former are chosen\n    for their parsimony and interpretability, whereas the latter\n    notoriously have too many terms to interpret.\n\n> Outside of industry, I've found that grad students in many scientific\n> domains are playing the role of the Data Scientist. One of our hires\n> for the Facebook Data team came from a bioinformatics lab where he was\n> building data pipelines and performing offline data analysis of a\n> similar kind. The well-known Large Hadron Collider at CERN generates\n> reams of data that are collected and pored over by graduate students\n> looking for breakthroughs [@hammerbacher2009: 84].\n\nIt seems likely that the phrase data scientist, as it was understood\nthen by the scientific community (and documented above), was transferred\nto this new domain by Hammerbacher's contact with some of its members.\n\nAt around the same time that Hammerbacher and Patel are said to have\ncoined the phrase data scientist, in October 2008 Hal Varian, chief\neconomist at Google, gave an interview to McKinsey's James Manyika in\nwhich he uttered the famous phrase, \"I keep saying the sexy job in the\nnext ten years will be statisticians \\[sic\\]\" [@mckinseycompany2009].\nThe interview was published on new year's day of 2009 and was\nimmediately processed by the blogosphere. Nathan Yau, who has a Ph.D. in\nstatistics from UCLA and runs the blog *FlowingData*, devoted to data\nvisualization, was quick to qualify Varian's use of the term\n\"statisticians\":\n\n> ... if you went on to read the rest of Varian's interview, you'd know\n> that by *statisticians*, he actually meant it as a general title for\n> someone who is able to extract information from large datasets and\n> then present something of use to non-data experts [@yau2009].\n\nHere's what Varian actually said:\n\n> I think statisticians are part of it, but it's just a part. *You also\n> want to be able to visualize the data, communicate the data, and\n> utilize it effectively*. But I do think those skills---of being able\n> to access, understand, and communicate the insights you get from data\n> analysis---are going to be extremely important. Managers need to be\n> able to access and understand the data themselves\n> [@mckinseycompany2009; emphases added].\n\nIn a follow-up post, \"Rise of the Data Scientist,\" Yau expands on his\nrevision to Varian's remarks by incorporating the comments of fellow\nblogger, Michael Driscoll of *Dataspora*, who also responded to the\nMcKinsey piece in a post entitled \"The Three Sexy Skills of Data Geeks.\"\nEchoing Yau, Driscoll wrote:\n\n> I believe that the folks to whom Hal Varian is referring are not\n> statisticians in the narrow sense, but rather people who possess\n> skills in three key, yet independent areas: statistics, data munging,\n> and data visualization [@driscoll2009].\n\nYau connects Driscoll's insight to Ben Fry's fertile concept of\n\"computational information design\" [@fry2004], which maps the fields of\ncomputer science, mathematics, statistics, data mining, graphic design,\nand human-computer interaction onto a data processing\npipeline---acquire, parse, filter, mine, represent, refine, and\ninteract. Whereas Driscoll called the role that integrates these fields\n\"statisticians or data geeks,\" tellingly equivocating, Yau used the term\ndata scientist:\n\n> And after two years of highlighting visualization on FlowingData, it\n> seems collaborations between the fields are growing more common, but\n> more importantly, computational information design edges closer to\n> reality. We're seeing *data scientists* -- people who can do it all --\n> emerge from the rest of the pack.\n>\n> . . .\n>\n> They have a combination of skills that not just makes independent work\n> easier and quicker; it makes collaboration more exciting and opens up\n> possibilities in what can be done. Oftentimes, visualization projects\n> are disjoint processes and involve a lot of waiting. Maybe a\n> statistician is waiting for data from a computer scientist; or a\n> graphic designer is waiting for results from an analyst; or an HCI\n> specialist is waiting for layouts from a graphic designer.\n>\n> Let's say you have several data scientists working together though.\n> There's going to be less waiting and the communication gaps between\n> the fields are tightened.\n>\n> How often have we seen a visualization tool that held an excellent\n> concept and looked great on paper but lacked the touch of HCI, which\n> made it hard to use and in turn no one gave it a chance? How many\n> important (and interesting) analyses have we missed because certain\n> ideas could not be communicated clearly? *The data scientist can solve\n> your troubles* [@yau2009: emphasis added].\n\nYau's definition of data scientist is consistent with that given in the\n*HBR* article written four years later. There the authors described data\nscientists as those who \"make discoveries while swimming in \\[the deluge\nof\\] data,\" \"bring structure to large quantities of formless data and\nmake analysis possible,\" \"identify rich data sources, join them with\nother, potentially incomplete data sources, and cleaning the resulting\nset,\" \"help decision makers shift from ad hoc analysis to an ongoing\nconversation with data,\" \"are creative in displaying information\nvisually and making the patterns they find clear and compelling,\"\n\"advise executives and product managers on the implications of the data\nfor products, processes, and decisions,' and so on. Replace the roles of\ndecision maker, executive, and product manager with scientist and\nengineer, and the definition is remarkably consistent with the classical\ndefinition as it had been developed in the years leading up to this\nshift.\n\nYau and Driscoll's response to Varian are notable because they\ndemonstrate how new the terms data science and data scientist were to\nthe general public at the time, and the manner in which these terms\ntransitioned from a narrow community of discourse to a much larger one.\nVarian and Driscoll used the term statistician, but both had to qualify\nthem significantly. That \"data scientist\" was not yet mainstream in 2009\ncan be seen in a *New York Times* article also written in response to\nthe McKinsey interview, entitled \"For Today's Graduate, Just One Word:\nStatistics\" [@lohr2009]. Here, the author was compelled to use the\nexpression \"Internet-age statistician\" to name the role described by\nVarian, and to qualify this usage in a manner similar to Varian:\n\n> Though at the fore, statisticians are only a small part of an army of\n> experts using modern statistical techniques for data analysis.\n> Computing and numerical skills, experts say, matter far more than\n> degrees. So the new data sleuths come from backgrounds like economics,\n> computer science and mathematics.\n\nWe may note here an important difference between how the two bloggers,\ncloser to the reality being described, and the established-media\njournalist represented the new development heralded by Varian: whereas\nLohr saw an expanded division of labor, Yau and Driscoll envisioned an\nentirely new role, something akin to the \"whole statistician\" described\nabove, although combining different elements. In any case, we see that\nit is at this precise point that the term \"data scientist\" begins to be\nused in the new context later described by the *HBR*.\n\nIn September 2010, two short but highly influential blog posts appeared\nthat sought to codify this conception of data science, which had by then\nreached the status of buzz word among participants of the technology\nconference circuit. The first was Drew Conway's \"The Data Science Venn\nDiagram,\" which defined the field as the intersection of three areas:\n\"hacking skills, math and stats knowledge, and substantive expertise\"\n[@conway2010]. Conway's post followed his attending an \"unconference to\nhelp O'Reily \\[sic\\] organize their upcoming Strata conference,\" where\nhe detected \"the utter lack of agreement on what a curriculum on this\nsubject would look like.\" His rationale for the three areas was the\nfollowing:\n\n> ... we spent a lot of time talking about \"where\" a course on data\n> science might exist at a university. The conversation was largely\n> rhetorical, as everyone was well aware of the inherent\n> interdisciplinary nature of the \\[sic\\] these skills; but then, why\n> have I highlighted these three? First, none is discipline specific,\n> but more importantly, each of these skills are on their own very\n> valuable, but when combined with only one other are at best simply not\n> data science, or at worst downright dangerous.\n\nOf interest here is, first, the need to define a curriculum for what was\nperceived to be a new field, which echoed previous efforts and presaged\nthe academic response that would eventually follow, and second, that\nConway's was essentially the classical definition applied to the context\nof what we might call information capitalism, the target audience of\nO'Reilly's conference. Although the role of statistics is emphasized,\nConway reduces its importance to \"knowing what an ordinary least squares\nregression is\" and goes on to assert that \"data plus math and statistics\nonly gets you machine learning.\" In other words, Conway's definition is\ncloser to Breiman's culture of algorithmic modeling than it is to that\nof data modeling. This is corroborated by the fact that by *data* Conway\nmeant \"a commodity traded electronically,\" i.e. that which is found in\ndatabases and shared over networks, as opposed to that which is\ncollected intentionally by designed experiments (A/B testing\nnotwithstanding).\n\nThe second post was Mason and Wiggins' \"A Taxonomy of Data Science,\"\nwhich was motivated by the need to make sense of the newly circulated\nterm:\n\n> Both within the academy and within tech startups, we've been hearing\n> some similar questions lately: Where can I find a good data scientist?\n> What do I need to learn to become a data scientist? Or more\n> succinctly: What *is* data science? [@mason2010]\n\nIn contrast to Conway's structural model, Mason and Wiggins proposed a\nprocessual one, based on \"what a data scientist does, in roughly\nchronological order: Obtain, Scrub, Explore, Model, and iNterpret (or,\nif you like, OSEMN, which rhymes with possum).\" In this model, most of\nthe activities normally associated with the classical definition of data\nscience---as listed in the *HBR* piece, for example---find a place. A\ndistinguishing feature of this definition is the modeling phase, which\nthey characterized as follows:\n\n> Whether in the natural sciences, in engineering, or in data-rich\n> startups, often the 'best' model is the most predictive model. E.g.,\n> is it 'better' to fit one's data to a straight line or a fifth-order\n> polynomial? Should one combine a weighted sum of 10 rules or 10,000?\n> One way of framing such questions of model selection is to remember\n> why we build models in the first place: to predict and to interpret.\n> While the latter is difficult to quantify, the former can be framed\n> not only quantitatively but empirically. That is, armed with a corpus\n> of data, one can leave out a fraction of the data (the \"validation\"\n> data or \"test set\"), learn/optimize a model using the remaining data\n> (the \"learning\" data or \"training set\") by minimizing a chosen loss\n> function (e.g., squared loss, hinge loss, or exponential loss), and\n> evaluate this or another loss function on the validation data.\n> Comparing the value of this loss function for models of differing\n> complexity yields the model complexity which minimizes generalization\n> error. The above process is sometimes called \"empirical estimation of\n> generalization error\" but typically goes by its nickname: \"cross\n> validation.\" Validation does not necessarily mean the model is\n> \"right.\" As Box warned us, \"all models are wrong, but some are\n> useful\". Here, we are choosing from among a set of allowed models (the\n> \\`hypothesis space', e.g., the set of 3rd, 4th, and 5th order\n> polynomials) which model complexity maximizes predictive power and is\n> thus the least bad among our choices.\n\nClearly, the authors sided with algorithmic modeling here; they argued\nfor prediction over interpretation by citing methods that have become\ncommonplace in the field. We also find here, for the first time, a\nclearly articulated pipeline of activity, echoing the partial sequences\nthat appear in previous definitions. Again, it is worth noting what data\nmeant in this context: data are to be obtained from preexisting sources,\nsometimes by scraping, and not produced. The skills required are far\nfrom those of the design-oriented data scientist of the Tokyo school:\n\n> Part of the skillset of a data scientist is knowing how to obtain a\n> sufficient corpus of usable data, possibly from multiple sources, and\n> possibly from sites which require specific query syntax. At a minimum,\n> a data scientist should know how to do this from the command line.\n> e.g., in a UN\\*X environment. Shell scripting does suffice for many\n> tasks, but we recommend learning a programming or scripting language\n> which can support automating the retrieval of data and add the ability\n> to make calls asynchronously and manage the resulting data. Python is\n> a current favorite at time of writing.\n\nNote that the idea of a data analyst *looking* for \"usable data\" as a\nfirst resort is anathema to that approach, at least in principle.\n\nIn 2011, O'Reilly, whose role in the promotion of data science is worth\nits own investigation, produced a series of influential blog posts and\nreports that sought to codify and amplify the definition developed by\nHammerbacher, Yau, Conway, Mason, and Wiggins. The definition produced\nwas consistent with the classical version, but strongly inflected by the\nnew business context. For example, Loukides' in \"What is Data Science?\"\ndescribed the field in terms consistent with what we have seen, focusing\non scale, new database technologies, and machine learning in the pattern\nset by Google. However, in this discourse these elements are combined in\nthe new concept of the \"data product,\" a good or service that integrates\nsurplus data to provide value to users:\n\n> The web is full of \"data-driven apps.\" Almost any e-commerce\n> application is a data-driven application. There's a database behind a\n> web front end, and middleware that talks to a number of other\n> databases and data services (credit card processing companies, banks,\n> and so on). But merely using data isn't really what we mean by \"data\n> science.\" A data application acquires its value from the data itself,\n> and creates more data as a result. *It's not just an application with\n> data; it's a data product*. Data science enables the creation of data\n> products [@loukides2011; emphasis added].\n\nThis emphasis on data products was echoed in Patil's essay, \"Building\ndata science teams,\" where the focus on data *applications* became\nessential to his definition of data scientist. Here he addressed the\nquestion, \"What makes a data scientist?\":\n\n> When Jeff Hammerbacher and I talked about our data science teams, we\n> realized that as our organizations grew, we both had to figure out\n> what to call the people on our teams. \"Business analyst\" seemed too\n> limiting. *\"Data analyst\" was a contender, but we felt that title\n> might limit what people could do. After all, many of the people on our\n> teams had deep engineering expertise.* \"Research scientist\" was a\n> reasonable job title used by companies like Sun, HP, Xerox, Yahoo, and\n> IBM. However, *we felt that most research scientists worked on\n> projects that were futuristic and abstract, and the work was done in\n> labs that were isolated from the product development teams*. It might\n> take years for lab research to affect key products, if it ever did.\n> Instead, *the focus of our teams was to work on data applications that\n> would have an immediate and massive impact on the business*. The term\n> that seemed to fit best was data scientist: those who use both data\n> and science to create something new [@patil2011; emphasis added].\n\nThe focus on data products at this point in history may be understood in\nlight of Zuboff's thesis that Google invented the business model of\n\"surveillance capitalism\" around 2003, based on the extraction of\n\"behavioral surplus,\" which was then exported to Facebook by Cheryl\nSandberg in 2008 and became widespread after that [@zuboff2019]. Zuboff\nmakes sense of the fact that in the O'Reilly papers Google's services\nwere frequently presented as exemplary data products, as well as the\nfact that the role of data scientist emerged at Facebook during the year\nof Sandberg's arrival there. It also sheds light on the nature of the\n\"immediate and massive impact\" of data products described by Patel: the\nprototypical data product is Google's advertising auctioning platform,\nwhich, as a result of applying its massive amounts of behavioral data to\npredict user behavior, \"produced a stunning 3,590 percent increase in\nrevenue in less than four years\" [@zuboff2019: Ch. 3, Part VI]. More\ngenerally, Zuboff sheds light on the practical context within which this\nnew iteration of data science emerged: in the heart of the system of\ncomputer-mediated economic transactions described by Varian\n[@varian2010]. In the previous period, when data science was imagined to\nbe located as the center of the infrastructure of data-driven science\n(as in the NSF report cited above), this setting is transferred to\ndomain of global, Internet-mediated commerce. Thus, just as the phrase\n\"data scientist\" leapt from one context to another at this time, so did\nthe infrastructural framework within which it made sense. Again, the\nmeaning of data science remains relatively unchanged from the classical\ndefinition; what changes is the context.\n\n::: comment\nIt may be good to insert a vignette about the RTCC as a business model.\nFrom SAGE to Google: The Role of Data Science in ...\n\nFocus on data as a social medium ...\n:::\n\nBy 2012, the terms data science and data scientist had trended widely in\nthe media, in part due to the amplifying effects of the *HBR* article,\nwhich employed Varian's catchy quip but adopted Yau's characterization\nof its referent. Articles in sources such as the New York Times and\nForbes regularly published stories on the demand for data scientists,\nprofiles of data scientists and data-driven companies, and opinion\npieces on its merits. In 2012, Forbes published a series of eight\narticles on \"What is a Data Scientist,\" which featured interviews with\nself-identified data scientists from IBM, Tableau, LinkedIn, Amazon, and\nother places, demonstrating the currency of the term in industry at that\ntime. In addition to media coverage, consulting firms such as Booz Allen\nand Gartner produced documents targeting at C-suite executives providing\nan overview of the field, including the definition of a data scientist\n(Herman et al. 2013; Laney 2012). Throughout these writings, the\ndefinitions provided were consistent with the newer meaning, roughly the\ncombination of computer competency, data mining, statistical knowledge,\ncommunication and visualization skills, and business acumen. In\naddition, the terms big data and data science were highly correlated;\nsentences like \"\\[d\\]ata scientists are the magicians of the Big Data\nera\" were frequent (Miller 2013).\n\n### A Note on \"Big Data\"\n\nAn important feature of the definition of data science in this period is\nits co-occurrence and close semantic association with the\noften-capitalized phrase \"big data.\" The phrase was used to refer to\nboth large amounts of data---retroactively identified with Laney's\nconcept of \"3D data,\" data with high \"volume, velocity, and variety\"\n(Laney 2001)---and to the assemblage of technologies and methods\nassociated with these data. The following definition from ZDNet is\ntypical:\n\n> \"Big Data\" is a catch phrase that has been bubbling up from the high\n> performance computing niche of the IT market. Increasingly suppliers\n> of processing virtualization and storage virtualization software have\n> begun to flog \"Big Data\" in their presentations. What, exactly, does\n> this phrase mean?\n>\n> . . .\n>\n> In simplest terms, the phrase refers to the tools, processes and\n> procedures allowing an organization to create, manipulate, and manage\n> very large data sets and storage facilities. Does this mean terabytes,\n> petabytes or even larger collections of data? The answer offered by\n> these suppliers is \"yes\" (Kusnetzky 2010).\n\nIndeed, the phrases big data and data science were often used\ninterchangeably. For example, consider this usage from a New York Times\npiece:\n\n> *The field known as \"big data\"* offers a contemporary case study. The\n> catchphrase stands for the modern abundance of digital data from many\n> sources --- the web, sensors, smartphones and corporate databases ---\n> that can be mined with clever software for discoveries and insights.\n> Its promise is smarter, data-driven decision-making in every field.\n> That is why data scientist is the economy's hot new job (Lohr 2014;\n> emphasis added).\n\nAlthough in use since the 1990s, the term big data was launched into the\npublic sphere (i.e. became viral) at nearly the same time as the terms\ndata science and data scientist: around 2008, when the British weekly\nscientific journal *Nature* published a special issue entitled \"Big\nData: Science in the Petabyte Era\" on the tenth anniversary of Google's\nincorporation (\"Community Cleverness Required\" 2008). By this time,\nGoogle's enormous success as a company founded on data mining had caught\nthe world's attention, including that of the scientific community, to\nthe point where the company had become something of a paradigm for\nscience. The issue was devoted to exploring how science ought to manage\nand exploit big data by following Google's lead through various data\nprocessing methods, from data mining to visualization to library\nscience. This connection between Google and science was also made by\n*WIRED*'s Chris Anderson at this time, in an issue also devoted to \"the\nPetabyte Age,\" who argued:\n\n> Our ability to capture, warehouse, and understand massive amounts of\n> data is changing science, medicine, business, and technology. As our\n> collection of facts and figures grows, so will the opportunity to find\n> answers to fundamental questions. Because in the era of big data, more\n> isn't just more. More is different (Anderson 2008b).\n\nAnderson argued that Google's successful application of model-free\nalgorithms, as in its ad auctioning system, showed that the scientific\nmethod was obsolete; or, more accurately, that science might \"learn from\nGoogle\" and by-pass the concern for theory building and focus on\nprediction. The parallel to Breiman's characterization of the\nalgorithmic modeling culture is clear here.\n\nThe rise of the term big data is indicative of an important shift in how\nthe problem of data impedance was conceptualized. Since at least the\n1960s, when the trope \"data deluge\" was invented apparently by NASA, the\nproblem of data surplus was always framed as a kind of disaster, as is\nevident from the image of a flood, and the semantically close and more\npopular phrase \"information explosion,\" implicitly likened to nuclear\nweapons by the frequent use of the image of the mushroom to signify\nexponential growth. With the success of the data-driven corporation on\nthe model of Google, these negative terms began to be replaced by the\nmore positive, or at least neutral, expression big data. In fact, one\nmay observe this transition in the simultaneous publication of the\n*Nature* and *WIRED* issues on the topic (cited above)---the former\nintroduces the new term while the latter uses the old, and both are\nlinked by the metonym of the \"petabyte\" era or age. Since then, the term\nbig data has been used to signify the context and opportunity within\nwhich the data science operates. For example, Patel and Davenport's 2012\narticle defined a data scientist as \"a high-ranking professional with\nthe training and curiosity to make discoveries in the world of big\ndata.\" This connection became a commonplace. In 2013, *Communications of\nthe ACM* published \"Data Science and Prediction,\" which also directly\nlinked big data to data science, while providing some flesh to the\nformer:\n\n> ... data science is different from statistics and other existing\n> disciplines in several important ways. To start, the raw material, the\n> \"data\" part of data science, is increasingly heterogeneous and\n> unstructured text, images, video often emanating from networks with\n> complex relationships between their entities. \\... Analysis, including\n> the combination of the two types of data, requires integration,\n> interpretation, and sense making that is increasingly derived through\n> tools from computer science, linguistics, econometrics, sociology, and\n> other disciplines. The proliferation of markup languages and tags is\n> designed to let computers interpret data automatically, making them\n> active agents in the process of decision making. Unlike early markup\n> languages (such as HTML) that emphasized the display of information\n> for human consumption, most data generated by humans and computers\n> today is for consumption by computers; that is, computers increasingly\n> do background work for each other and make decisions automatically.\n> This scalability in decision making has become possible because of big\n> data that serves as the raw material for the creation of new\n> knowledge; Watson, IBM's \"Jeopardy!\" champion, is a prime illustration\n> of an emerging machine intelligence fueled by data and\n> state-of-the-art analytics (Dhar 2013: 64).\n\nHere, big data is linked to both data science and to the *kinds* of data\nthat have been associated with the field since the AFCRL, in addition to\ntextual data specific to the Internet and the Web.\n\n## The 2010s\n\n### The Disconnect with Statistics\n\nAmong the most significant developments in the years immediately\nfollowing the emergence of what I have called big data science was the\nexplicit perception by professional statisticians that all of this\noccurred independently of their field, and that statisticians would do\nwell to take advantage of the new interest in data that was sweeping the\nbusiness world. In a series of surprisingly candid editorials in\n*AmStatNews*---the membership magazine of the American Statistical\nSociety---no fewer than three succeeding presidents of the organization,\nfrom 2012 to 2014, offered their views on what they saw as a troubling\n\"disconnect\" between the field of statistics and data science.\n\nThis disconnect---between the self-perception among statisticians that\nthey already are data scientists and their exclusion from real\ndevelopments in industry and the media under the name of big data---is\ncaptured by this anecdote given by Marie Davidian in her column\n(entitled \"Aren't We Data Scientists?\"):\n\nI was astonished to review the list of founding members \\[of the\nNational Consortium for Data Science (NCDS) based in North Carolina\\]\nand see that not only is my university (North Carolina State) a founding\nmember, but so are Duke University and UNC-CH. Along with SAS Institute;\nResearch Triangle Institute International; NIH's National Institute for\nEnvironmental Health Sciences; IBM; and several other institutions,\nbusinesses, and government agencies that employ numerous statisticians.\nThe member representatives listed on the website from NC State, Duke,\nand UNC-CH are computer scientists/engineers, and among all 17\nrepresentatives, *there is not one statistician*. (Davidian 2013: 3;\nemphasis added.)\n\nThe gap was noted a year earlier by Robert Rodriguez, but without the\nsurprise:\n\nA recurring theme in Big Data stories is the scarcity of \"data\nscientists\"---the term used for people who can draw insights from large\nquantities of data. This shortage was highlighted in an April 26, 2012,\n*Wall Street Journal* article titled, \"Big Data's Big Problem: Little\nTalent\" (Rooney 2012). The question \"What is a data scientist?\" is still\nbeing debated (see the articles with this title at Forbes). However,\n*there is consensus that data scientists must be innovative problem\nsolvers with expertise in statistical modeling and machine learning,\nspecialized programming skills, and a solid grasp of the problem\ndomain*. Hilary Mason, chief data scientist at bitly, adds that \"*data\nscientists are responsible for effectively communicating the things that\nthey learn. That might be creating visualizations or telling the story\nof the question, the answer, and the context*.\" (Rodriguez 2012: 3-4;\ncitation and emphases added.)\n\nIt is notable that Rodriguez clearly recognized the reality behind the\ndisconnect, conceding that \"our profession and the ASA have not been\nvery involved in Big Data activities.\" He did not trivialize the\nconcepts of big data and data science; instead, he patiently explained\ntheir distinctive features and provided suggestions for how\nstatisticians can add value to these developments going forward. He\nsuggested that statisticians should \"view data science as a blend of\nstatistical, mathematical, and computational sciences,\" and focus their\nefforts on how to \"extract value from data not only by learning from it,\nbut also by understanding its limitations and improving its quality.\nBetter data matters because simply having Big Data does not guarantee\nreliable answers for Big Questions.\"\n\nIn a subsequent editorial co-authored with the two succeding presidents\nof the ASA, Rodriguez's recognition of the absence of statistics from\ndata science and his strategy to focus on what statisticians do best is\namplified and augmented:\n\nIdeally, statistics and statisticians should be the leaders of the Big\nData and data science movement. Realistically, we must take a different\nview. While our discipline is certainly central to any data analysis\ncontext, *the scope of Big Data and data science goes far beyond our\ntraditional activities.* As Bob \\[Rodriguez\\] noted in his column, the\nsheer scale and velocity of the data being generated from multiple\nsources requires new data management and computational paradigms. New\ntechniques for analysis and visualization must be developed. And\ncommunication and leadership skills are critical.\n\nWe believe we should focus on what we need to do as a profession and as\nindividuals to become valued contributors whose unique skills and\nexpertise make us essential members of the Big Data team. . . . We know\nstatistical thinking---our understanding of modeling, bias, confounding,\nfalse discovery, uncertainty, sampling, and design---brings much to the\ntable. We also must be prepared to understand other ways of thinking\nthat are critical in the Age of Big Data and to integrate these with our\nown expertise and knowledge.\n\nWe have had many discussions---among ourselves and with ASA members who\nare familiar with Big Data---about strategies for achieving this\npreparation and integration. These discussions have led to our joint ASA\npresidential initiative to establish the statistical profession as a\nvalued partner in Big Data activities and to position the ASA in a\nproactive and facilitating role. *The goal is to prepare members of our\nprofession to collaborate on Big Data problems.* Ultimately, this\npreparation will bridge the disconnect between statistics and data\nscience (Rodriguez, Davidian, and Schenker 2013; emphases added).\n\nNot all academic statisticians were willing to concede the point that\ndata science \"goes far beyond our traditional activities.\" Indeed, many\nviewed data science as an invader of their territory. Bin Yu, then\npresident of the Institute of Mathematical Statistics, exhorted her\ncolleagues to \"own data science\" (Yu 2014), echoing Davidian's\nexasperatated observation (and no doubt the sentiment of many) that\nstatisticians \"already are\" data scientists. To make her point, she\ndefined the core components of data science---statistics, domain\nknowledge, computing, teamwork, and communication---and then traced each\nof these to the traits of various ancestors in her field. In this\nnarrative, Harry Carver, Herman Hollerrith, and John Tukey are all data\nscientists *avante la lettre*. Indeed, in Yu's narrative Carver is an\n\"early machine learner,\" which allow her to claim machine learning as a\nprovince of statistics.\n\n### The Academic Response\n\nAfter 2012, the field of data science and the cluster of associated\nactivities associated with it grew exponentially. As mentioned above,\nthis growth was associated with a high demand for data scientists, a\nstory that continues to be covered by the news media. The response by\ninstitutions of higher education to train data scientists to meet\nindustry demand was rapid and pronounced. Hundreds of master's degree\nprograms in data science and closely related fields were established in\nthe United States, often associated with the formation of institutes of\ndata science. More recently, a handful of doctoral programs and schools\nof data science have emerged, along with undergraduate offerings to meet\nincreasing student demand. The trend to create degree programs for the\nfield continues.\n\nOne effect of these developments has been to stimulate a preferential\nattachment process within the network of disciplines that constitute the\nacademy: as a field representing the \"sexiest job of the 21^st^\ncentury,\" attracting students, gifts, and internal resources, many\nadjacent disciplines---from systems engineering and computer science to\nstatistics and a variety of quantitative and computational\nsciences---have sought to associate themselves with the field. Indeed,\nbecause data science per se has had no history in the academy, these\ncontiguous fields have provided the courses and faculty out of which the\nmajority of data science programs have been built. The result is that\ndata science has become a complex and internally competitive patchwork\nof industrial and academic interests and perspectives, reflecting the\nbroader engagement of society with data and its analysis beyond the\nconcept of data science inherited from industry.\n\nYu's argument that statistics should take over data science is made\nagain later, and more thoroughly, by Donoho in \"50 Years of Data\nScience\" (Donoho 2017), which is essentially a manifesto for the\nannexation of data science by departments of statistics in response to\nthe proliferation of academic programs associated with the new field. He\ncharts out the territory of \"Greater Data Science\" (GDS)---a playful\nreversal of Chambers' earlier plea for a \"greater statistics\" that would\nbe \"based on an inclusive concept of learning from data\"---and places\nstatistics at its center (Chambers 1993: 1). He locates GDS in a\ngenealogy that begins with data analysis---a practice envisioned in the\n1960s by his mentor at Princeton, the legendary mathematician John\nTukey, who serves as the founding ancestor in this legitimation\nnarrative. GDS is thus defined as \"a superset of the fields of\nstatistics and machine learning, which adds some technology for 'scaling\nup' to 'big data'\" (Donoho 2017 \\[2015\\]: 745). He also attempts to\ndeflate the concept of big data, so central to contempory data science,\nby citing the Holerith's punched card system, which was invented to\nprocess the unexpectedly large volume of data produced by the 1890 US\ncensus, as an early instance and therefore nothing new. Like Yu,\nDonoho's argument is that, beyond the introducing a few useful\ntechnologies, data science as a whole is nothing new. It is a scandal\nthat it has emerged outside of the field of statistics and is\nrepresented in the media as a distinct field.\n\nDonoho's essay has been criticized for downplaying the contribution of\ncomputational technology to data science. In his response to it, Chris\nWiggins, Chief Data Scientist of the *New York Times* and a professor at\nColumbia, sensed this and asserted that data science is a form of\nengineering that will be defined by its practitioners, not by academics\ntrying to turn it into a (pure) science. In his response, Sean Owen,\nDirector of Data Science at Cloudera, argued that Donoho's history\nexcluded the significant contributions of data engineering (Donoho 2017:\n764). Elsewhere, Bryan and Wickham pointed out that, like many\nstatisticians, Donoho mistakenly relegated computational work to\nsuperficial status while also missing \"the full process of analysis\" in\nwhich statistics \"is but one small part\" (Bryan and Wickham 2017). In\nhis defense, Donoho acknowledged his bias, but justified it by noting\nthat although technological know-how is important, technologies are\ntransitory and prone to rapid obsolescence, and therefore \"the academic\ncommunity can best focus on teaching broad principles---'science' rather\nthan 'engineering'\" (Donoho 2017: 765). *Scientia longa, brevis ars.*\n\nIt is beyond the scope of this essay to fully evaluate the arguments of\nDonoho and Yu. Suffice it to say that when Facebook was hiring data\nscientists in 2008, the fact that someone's academic field could claim\nHollerith and Carver as data scientists would not have improved that\ncandidate's chances of being hired. What is significant here for\nunderstanding the history of data science is the social underpinning of\nthe observed disconnect between members of the established field of\nstatistics and those of the emerging one of data science. By 2012,\nBreiman's observation that the developments in algorithmic modeling, and\nmore generally data mining, \"occurred largely outside statistics in a\nnew community,\" was proven to be both true and prescient: that new\ncommunity became one of the primary tributaries to data science, and the\nlong standing opposition of statistics toward the beliefs of that\ncommunity---evident in Donoho and the predecessors he cites in the 1990s\nand early 2000s---became manifest.\n\n## Summary\n\nMoving between social fields\n\n1.  Military-Industrial\n    1.  AFCRL, VA, WSMR, etc.\n    2.  Dynalectron, Mohawh, etc.\n2.  Government-Scientific\n    1.  NOAA, NASA, NIMS (?)\n3.  Academia\n    1.  Naur\n    2.  Japan\n    3.  US\n4.  Business (Silicon Valley)\n    1.  Facebook, LinkedIn\n    2.  O'Reilly\n\n# Interpretation\n\nLet us stop here, roughly at the point where data science becomes widely\nknown and legitimate in the eyes of industry, and both accepted and\ncontested within academia, and which characterizes the current period.\nWhat can we glean from this historical outline? Several themes emerge.\nMost significantly, it has been established that the term data science\nper se dates back to the early 1960s with the formation of the Data\nSciences Laboratory in Cambridge, Massachusetts, and this usage was\nsurprisingly close to its current one. To review, the esseential\nelements were there: the presence of big data (properly understood) and\nthe use of both computational machinery and artificial intelligence to\nmake sense of it. Morevoer, this original meaning remains surprisingly\nconsistent in the decades that follow, even as the term developed and\naccreted new senses. This development can be characterized as having\nthree main phases resulting in three major variant definitions of the\nterm: (1) Computational Data Science, (2) Statistical Data Science, and\n(3) Big Data Science. In addition, we can add a fourth definition,\ninchoate and currently being developed, that we may call Academic Data\nScience. These are described below.\n\n## Four Definitions\n\n### DS~1~: Computational Data Science\n\nThis is the original, or classical, definition of data science that\nbegins with the Data Sciences Laboratory and is taken up, at first in\nspirit if not in name, by organizations like CODATA during the same era.\nData science in this definition is *the science of data in support of\nscience and decision-making*. This definition also includes the concept\nof datalogy developed by Naur as well as the data processing know-how of\ncorporations like Mohawk Data Science, but it is primarily a field\ndeveloped by and for scientists and engineers to handle the problems\narising from data surplus, culminating in the so-called fourth paradigm\nof science. That this field by this name persists and becomes\nestablished through the current era is evident in the fact that the term\n\"data scientist\" had currency in places like *New Scientist*, *TheTimes*\nof London, and other news sources in the 1990s and 2000s. In addition,\ndata science in this sense is the subject of high level reports from the\nNSF and JISC in the 2000s. That this definition persists to this day can\nbe found in examples like the work of the Dutch data scientist\nDemchenko, who assigns data management, curation, preservation central\nplaces in the definition of data science (Demchenko 2017).\n\nEssential to this definition is a focus on what is eventually called big\ndata and issues arising from its curation and processing. Importantly,\nthis definition also frames data surplus as a positive condition that\nmakes possible new ways doing science, i.e. the fourth paradigm view of\nsicence. Methodologically, this definition also embraces AI, machine\nlearning, and data mining methods that may or may not be principled from\na strict statistical point of view. It also embraces statistical\nmethods, but from the practical perspective of scientists are who often\nnot concerned with the concerns of pure, mathematical statisticians.\n\nArguably this definition also includes adjacent work in computer science\nof data processing, information retrieval, and information science which\nled to the invention and development of databases and general theories\nof data. Eventually, the fruits of this work would lead to the\nconditions of data impedance that led to data mining, a practice that\nconverted the vice of surplus into a virtue by establishing a mutually\nbeneficial relationship between surplus digital data and machine\nlearning.\n\n### DS~2~: Statistical Data Science\n\nBy statistical data science, I refer to the usage developed by Hayashi\nand Ohsumi (the Tokyo School) and the American statisticians Wu,\nKettenring, and Cleveland, as well as Donoho. These statisticians\nimplored their colleagues, unsuccessfully, to adopt the term data\nscience in order to rebrand their discipline in response to the\novershadowing effects of computational statistics and data mining that\nwere being felt in the 1990s.\n\nThe essential characteristics of this definition are the renewed\ncommitment to Tukey's conception of data analysis and, more generally,\nan appreciation of the foundational role of data in statistics, along\nwith an exhortation to take seriously recent developments in computer\nscience in areas ranging from machine learning to databases. However,\nthese technologies are to be incorporated with the admonition to avoid\nthe practices of data mining, which, on its own, is considered\nunprincipled. Indeed, this definition may be seen primarily as an effort\nto correct what are perceived to be the fruitful but misguided efforts\nof data mining by grounding its computational methods in a\nmathematically sound framework.[^ds-from-1963-to-2012-19]\n\n[^ds-from-1963-to-2012-19]: The works of Hastie, Tibshirini, and their\n    coauthors are perhaps the most successful exemplars of this\n    definition; their work incorporates enthusiastically data mining,\n    but always within the encompassing framework of statistical thinking\n    that effectively domesticates the field (Hastie, Tibshirani, and\n    Friedman 2009; Efron and Hastie 2016).\n\nRegarding the relationship of data science to the computational\ntechnologies on which it depends, this definition treats them as\nessential but external to core practice. Languages, servers, and\ndatabases are thought of as an environment within which the analyst\ncarries out an essentially mathematical set of tasks with greater\nefficiency, not as the medium through which one thinks about the world.\nTheir net effect on the work of statistics is considered to be a\ndifference in degree, not in kind.\n\n### DS~3~: Big Data Science\n\nBy big data science, I refer to the form of data science that emerged in\nthe context of web companies like Google and Facebook and become both\nviral and paradigmatic after being anointed by *HBR* in 2012. As we have\nseen, this definition transfers the classical, computational definition,\ndeveloped within the military-industrial context of the 1960s, to the\ncontext of the Silicon Valley social media firm, or what Zuboff has\ncalled surveillance capitalism. The conditions of data impedance that\nattended the rise of Big Science after WWII are embraced and become the\nfoundation of a new business model that in turn becomes a model for all\nother firms and sectors to imitate, from the automotive industry to\nmedicine.\n\nOne of the distinctive features of this definition is the close\nassociation with big data, in perception if not always in reality, as\nboth a set of new technologies to manage 3D data and a set of\n\"unreasonably effective\" methods to convert these data into value.\nAnother feature is the focus on data wrangling, the work required to\nconvert the widely varying formats and conditions of data in the wild\ninto the standard analytical form. In addition to these features, and\nconsistent with Varian's remarks in the 2008 McKinsey interview, big\ndata science embraces a suite of activities that connect these practices\nto the context of business and decision-making, such as visualization,\ncommunication, business acumen, and a focus on marketable data products.\n\nIt follows that Donoho is incorrect in asserting that \"\\[w\\]e can\nimmediately reject 'big data' as a criterion for meaningful distinction\nbetween statistics and data science\" (Donoho 2017: 747). The assemblage\nof computational technology associated with big data is the condition of\npossibility of data science in this definition, its *sine qua non*. It\nis impossible to imagine this kind of data science without the\ninfrastructure of data generating machinery, high-performance\ncomputating architectures, scalable database technologies such as Hadoop\nand its descendants, and data-savvy programming languages such as R,\nPython, and Julia, and, to a high degree, the availability of extant\ndatasets on the web. Indeed, the connection between this kind of data\nscience and the technology stack on which it stands is so close that the\nrelationship between technology and science becomes blurred, leading to\nrevolutionary proclamantions of new kinds of science and conservative\nreactions to such claims (such as Donoho's).\n\n### DS~4~: Academic Data Science\n\nBy academic data science, I refer to the ongoing reception of big data\nscience by the academic community in response to the demand for data\nscientists across all sectors of society. The idea of data science has\ninfluenced the academy in two ways: first, by stimulating the production\nof degree programs to meet workforce demands, and second, by providing a\nmodel for effective knowledge production in the context of pervasive\ndata and data technologies. Both of these influences have given rise to\nthe secondary effect of bringing to the surface and aggregating the\nmyriad other forms of data-centric and analytic activities already being\nconducted in the academy (and elsewhere) for years, from statistics to\noperations research to e-sceince, all of which have claims to be\n\"already doing data science.\" This situation has led to current crisis\nin the definition of data science that is has produced responses such as\nDonoho's as well as the current essay.\n\nBased on personal experience, I believe that the term data science\nwithin the academy has in recent years been nudged in the direction of\nbeing identified with an expanded form of statistics (DS~2~), regardless\nof whether its programs are \"owned\" by departments of statistics or\nnot. This is because of the great authority of the field of statistics\nwithin the academy, as well as a general skepticism toward\nindustry-generated categories by academics, many of whom dismiss the\nterms big data and data science as buzzwords. This has put pressure on\ndevelopers of data science programs to become academically legitimate in\nthe eyes of their peers and administrators. The shift in meaning is also\ndue, quite frankly, to the co-opting of the phrase by departments of\nstatistics to both cash in on it's name recognition and stem the tide of\nwhat are perceived to be its negative qualities. This tendendency has\nhad the effect of flooding the market of data scientstis with de facto\ndata analysts who are unable to perform the work that many in industry\nhad previously sought under the sign of data scientist. And this has\nproduced a counter-effect within industry to invent new categories of\nwork, such as the data engineer and the data software developer. In\nreality, these new categories are surprisingly close in meaning to the\noriginal category of data-processing scientist that was coined in the\n1950s in the context of data reduction and other work that eventually\nbecame associated with the AFCRL Data Sciences Laboratory and with\nscientific research data management in general.\n\nThis is an unfortunate state of affairs. The great value of data science\nhas been in its cultivation of the fertile land between the science and\nengineering of data opened up by the great advances in data generating\nand processing machinery for both science and industry. It is also\nunfortunate because as the academy produces a definition of data science\nat odds with what science and industry need, the latter are once again\nleft to fend for themselves, creating their own ad hoc educational\nresources to convert computer scientists and other adjacent role into\ndata engineers. A rose is a rose by another other name.\n\n## Data Impedance\n\nTo summarize, the field of data science has a surprisingly consistent\nand durable history, even if, on the ground, the individual actors in\nthis social drama have not been not aware of this fact. The original\nconstitution of the field, DS~1,~ survives to the present day, providing\nthe backbone and the foil for each of the following configurations. For\nif DS~2~ is clearly a reaction to the effects of the first, DS~3~ is a\nrevival of DS~1~ in a new key. Wu and Hammberbacher may not have been\naware that they were borrowing a term from one context and applying it\nto another analogous one, but social facts are rarely perceived as such\nby the individuals who participate in them.\n\nI hypothesize that the source of this continuity is a persistent\nsituation in which it makes sense to use the term data science. The term\nis motivated in at least two ways. First, it is motivated semiotically\nby virtue of its complementary relationship to other extant categories\nwhich constitute the repertoire available concepts and terms. Data\nscience is not computer science nor information science nor statistics\nnor data analysis but adjacent to each of these. In each case, the term\nwas selected from the sample space of these other terms, which always\nremained possible choices. The fact that they were not selected is what\nis significant. Second, the term was and is motivated by the role that\nit plays in referencing a persistent assemblage of material conditions\nthat emerged during the post war era and continues to this day. In\naddition to being embodied by the SAGE system that arguably motived the\ninitial coinage of data science, those material conditions gave birth to\nthe Internet, whose construction was first conceived shortly after 1957\nin response to the launch of Sputnik by the Soviet Union, and to the\nfield of data processing and everything associated with it, including\nthe development of databases and the refining of the concept of data\nitself.\n\nI have chosen the term data impedance to characterize this persistent\nsituation. Again, by this term I mean the disproportion between the\nsurplus of data generated by the machinery of data production, and the\nrelative scarcity of computational power and methods to process these\ndata and extract value from them. To be sure the condition of impedance\nhas been part of the human condition since the formation of states which\nrequire the use of media to function. By media, I mean external records\nthat must be stored and interpreted to be useful. Such records range\nfrom the quipus of the ancient Inca, to the hieroglyphic writing systems\nof the ancient Maya and Egyptians, to those of Asia and Europe. What is\nhistorically unique about the post-war condition of data impedance is\nthat it occurs within the milieux of digital and electronic data\ncharacterized as the input and output of computational machinery.\nAlthough other forms of data are clearly part of the condition I am\ndescribing, these technologies are at the center and what gives the\nunique historical character to the condition I am describing and to data\nscience.\n\n## Data mining vs data analysis\n\nA final theme one may observe in this history is that data science has\nbeen a contested term at least since the 1990s, when statistical data\nscience (DS~2~) emerged in Japan and the US in response to the\ndevelopments of classical, computational data science. As we have seen,\nthis response was partly an attempt to embrace the advances made by\ncomputational data science (DS~1~) and partly an effort to correct what\nwere perceived to be the excesses of this approach. The marginalization\nof computational technology in this definition of data science is\nconsistent with the larger conflict between what Breiman famously called\n\"two cultures\" in the work of statistics.[^ds-from-1963-to-2012-20]\nBreiman's trope provides a useful framework for capturing the\nepistemological differences between the two communities associated with\nthese definitions. On the one hand, we have the data analysts, on the\nother the data miners. The former, descendants of Tukey, remained\nfaithful to the mission of statistics to provide a mathematically\nprincipled methodology for working with data. Ideally, all data were\nunderstood to be produced by information generating mechanisms that can\nbe described by interpretable models and, in the ideal case,\nparametrically. Even Bayesian methods, long held back by their\ncomplexity, but reborn with the rise of computational methods like MCMC\nand Gibbs Sampling, were reined in by the data modeler's ethos. The\nlatter, the data miners, unfettered by such requirements,\nenthusiastically applied the newer and rapidly developing world of\nalgorithms and, more generally, computational thinking to the data\nsurplus that was inundating science, government, and industry.\n\n[^ds-from-1963-to-2012-20]: It is no coincidence that Breiman's essay\n    appeared at about the time some academic statisticians sought to\n    rebrand their field as data science in an attempt to integrate the\n    gains of computational technology while purging it of the\n    methodological sins of data mining. Although Breiman is sometimes\n    counted among those wishing to rebrand statistics as data science,\n    the substance of his remarks, which did not reject the spirit of\n    data mining, went against the grain of that movement.\n\nTo conclude, an authentic definition of data science would embrace the\nterm's history. As we have seen, this history is not merely\netymological; the term indexes a persistent situation that continues to\nmotivate the current practice of data science in industry and science.\nAcademics would do well to embrace this and avoid what may be called the\nfallacy of purism as we seek to make sense of the field as a body of\nknowledge. This means embracing the oppositions between data analysis\nand data mining, and between science and engineering, as a core,\nanimating tensions in the field that may be cultivated for its\ngenerativity.\n\n# References {#references .list-paragraph}\n\nAFCRL. 1963. \"Report on Research at AFCRL: July 1962 - July 1963.\"\nBedford, Mass.: Air Force Cambridge Research Laboratories.\n\n---------. 1967. \"Report on Research at AFCRL: July 1965 - June 1967.\"\nAFCRL-68-0039. Survey of Programs and Progress. Bedford, Massachusetts:\nAir Foce Cambridge Research Laboratories.\n\n---------. 1970. \"Report on Research at AFCRL: July 1967 -- June 1970.\"\nAFCRL-71-0022. Bedford, Massachusetts: Air Foce Cambridge Research\nLaboratories.\n\n---------. 1973. \"Report on Research at AFCRL: July 1970 - June 1972.\"\n\nAltshuler, Edward E. 2013. *The Rise and Fall of Air Force Cambridge\nResearch Laboratories*. CreateSpace Independent Publishing Platform.\n\nAlvarado, Rafael, and Paul Humphreys. 2017. \"Big Data, Thick Mediation,\nand Representational Opacity.\" *New Literary History* 48 (4): 729--49.\nhttps://doi.org/10.1353/nlh.2017.0037.\n\nAnderson, Chris. 2008a. \"The End of Theory: The Data Deluge Makes the\nScientific Method Obsolete.\" *Wired*, June 23, 2008.\nhttp://www.wired.com/science/discoveries/magazine/16-07/pb_theory.\n\n---------. 2008b. \"The End of Theory: The Data Deluge Makes the\nScientific Method Obsolete.\" *Wired*, June 23, 2008.\nhttp://www.wired.com/science/discoveries/magazine/16-07/pb_theory.\n\nAndo, A., and G. M. Kaufman. 1966. \"Evaluation of an Ad Hoc Procedure\nfor Estimating Parameters of Some Linear Models.\" *The Review of\nEconomics and Statistics* 48 (3): 334--40.\nhttps://doi.org/10.2307/1927089.\n\n\"Announcements.\" 1964. *Nature* 203 (4952): 1337--1337.\nhttps://doi.org/10.1038/2031337d0.\n\nAppropriations, United States Congress House. 1958. *Second Supplemental\nAppropriation Bill: 1958, Hearings \\... 85th Congress, 2d Session*.\n\n---------. 1965. *Independent Offices Appropiations for 1966: Hearings\n\\... 89th Congress, 1st Session, Part 3*.\n\nAppropriations, United States Congress House Committee on. 1970.\n*Department of Defense Appropriations for 1971: Hearings \\...\nNinety-First Congress, Second Session*. U.S. Government Printing Office.\n\nBell, Gordon, Jim Gray, and Alex Szalay. 2007. \"Petascale Computational\nSystems.\" *ArXiv:Cs/0701165*, January. http://arxiv.org/abs/cs/0701165.\n\nBerners-Lee, Tim, and Mark Fischetti. 2008. *Weaving the Web: The\nOriginal Design and Ultimate Destiny of the World Wide Web by Its\nInventor*. Paw Prints.\n\nBorne, Kirk D., Suzanne Jacoby, K. Carney, A. Connolly, T. Eastman, M.\nJ. Raddick, J. A. Tyson, and J. Wallin. 2009. \"The Revolution in\nAstronomy Education: Data Science for the Masses.\" *ArXiv:0909.3895\n\\[Astro-Ph, Physics:Physics\\]*, September.\nhttp://arxiv.org/abs/0909.3895.\n\nBreiman, Leo. 2001. \"Statistical Modeling: The Two Cultures.\"\n*Statistical Science* 16 (3): 199--231.\nhttps://doi.org/10.1214/ss/1009213726.\n\nBroman, Karl. 2013. \"Data Science Is Statistics.\" *The Stupidest\nThing\\...* (blog). April 5, 2013.\nhttps://kbroman.wordpress.com/2013/04/05/data-science-is-statistics/.\n\nBryan, Jennifer, and Hadley Wickham. 2017. \"Data Science: A Three Ring\nCircus or a Big Tent?,\" December. https://arxiv.org/abs/1712.07349v1.\n\nBryce, G. Rex, Robert Gould, William I. Notz, and Roxy L. Peck. 2001.\n\"Curriculum Guidelines for Bachelor of Science Degrees in Statistical\nScience.\" *The American Statistician* 55 (1): 7--13.\n\nBurkett, Ron. 2003. \"Burkett Announces His Retirement as Director of\nMuseum,\" 2003.\n\nChambers, John M. 1993. \"Greater or Lesser Statistics: A Choice for\nFuture Research.\" *Statistics and Computing* 3 (4): 182--84.\nhttps://doi.org/10.1007/BF00141776.\n\nChynoweth, Carly. 2008. \"Communication Is Key for Programmers.\" *The\nTimes*, May 8, 2008.\nhttps://advance.lexis.com/document/?pdmfid=1516831&crid=e0aaeba2-6f62-410b-bc54-a11d5f8f5253&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4SFX-GS40-TX38-S09K-00000-00&pdcontentcomponentid=10939&pdteaserkey=sr30&pditab=allpods&ecomp=gb63k&earg=sr30&prid=19e1f7de-2617-49de-93da-706f9a17e95e.\n\nCleveland, William S. 2001. \"Data Science: An Action Plan for Expanding\nthe Technical Areas of the Field of Statistics.\" *International\nStatistical Review / Revue Internationale de Statistique* 69 (1):\n21--26. https://doi.org/10.2307/1403527.\n\nCodd, Edgar F. 1970. \"A Relational Model of Data for Large Shared Data\nBanks.\" *Communications of the ACM* 13 (6): 377--87.\n\n\"Community Cleverness Required.\" 2008. *Nature* 455 (7209): 1--1.\nhttps://doi.org/10.1038/455001a.\n\nConway, Drew. 2010. \"The Data Science Venn Diagram.\" *Drew Conway*\n(blog). September 30, 2010.\nhttp://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram.\n\nCorliss, William R. 1967. *Scientific Satellites*. Scientific and\nTechnical Information Division, National Aeronautics and Space\nAdministration.\n\nCrawford, Jr., Perry. 1974. \"On the Connections between Data and Things\nin the Real World.\" In *Management of Data Elements in Information\nProcessing, Proceedings*, 51--57.\n\n*Data Science Journal*. n.d. \"About This Journal.\" Accessed July 1,\n2020. http://datascience.codata.org/.\n\nDavenport, Thomas H., and D. J. Patil. 2012. \"Data Scientist: The\nSexiest Job of the 21st Century.\" Harvard Business Review. October 1,\n2012.\nhttps://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\nDavidian, Marie. 2013. \"Aren't We Data Science?\" *AMSTAT News: The\nMembership Magazine of the American Statistical Association*, no. 433:\n3.\n\nDavis, Miriam. n.d. \"The Canary That Forgot Its Song.\"\n\nDemchenko, Yuri. 2017. \"The Emerging Role of the Data Scientist and the\nExperience of Data Science Education at the University of Amsterdam.\" In\n.\n\nDhar, Vasant. 2013. \"Data Science and Prediction.\" *Communications of\nthe ACM* 56 (12): 64--73. https://doi.org/10.1145/2500499.\n\nDonoho, David. 2017. \"50 Years of Data Science.\" *Journal of\nComputational and Graphical Statistics* 26 (4): 745--66.\nhttps://doi.org/10.1080/10618600.2017.1384734.\n\nDriscoll, Michael E. 2009. \"The Three Sexy Skills of Data Geeks.\"\n*Dataspore Blog* (blog). May 27, 2009.\nhttps://web.archive.org/web/20090530074011/dataspora.com/blog/sexy-data-geeks/.\n\nEfron, Bradley, and Trevor Hastie. 2016. *Computer Age Statistical\nInference*. Vol. 5. Cambridge University Press.\n\nFayyad, Usama M, Gregory Piatetsky-Shapiro, Padhraic Smyth, and others.\n1996. \"Knowledge Discovery and Data Mining: Towards a Unifying\nFramework.\" In *KDD*, 96:82--88.\n\nFrank, Michael C., and Noah D. Goodman. 2012. \"Predicting Pragmatic\nReasoning in Language Games.\" *Science* 336 (6084): 998--998.\nhttps://doi.org/10.1126/science.1218633.\n\nFriston, Karl J., and Christopher D. Frith. 2015. \"Active Inference,\nCommunication and Hermeneutics.\" *Cortex; a Journal Devoted to the Study\nof the Nervous System and Behavior* 68 (July): 129--43.\nhttps://doi.org/10.1016/j.cortex.2015.03.025.\n\nFry, Benjamin Jotham. 2004. \"Computational Information Design.\" Thesis,\nMassachusetts Institute of Technology.\nhttps://dspace.mit.edu/handle/1721.1/26913.\n\nGarfinkel, Simson. 2000. *Database Nation: The Death of Privacy in the\n21st Century*. O'Reilly Media, Inc.\n\nGeertz, Clifford. 2017. *The Interpretation of Cultures*. Basic Books.\n\nGoldfarb, C. F. 1970. \"An Online System for Integrated Text Processing.\"\n*Proceedings of the American Society for Information Science* 7:\n147--50.\n\nGreen, Tom. 2010. *Bright Boys: The Making of Information Technology*.\nCRC Press.\n\nGroves, Robert. 2018. \"Hermeneutics and Bayesian Statistics.\" *The\nProvost's Blog* (blog). January 10, 2018.\nhttps://blog.provost.georgetown.edu/hermeneutics-and-bayesian-statistics/.\n\nHalevy, A., P. Norvig, and F. Pereira. 2009. \"The Unreasonable\nEffectiveness of Data.\" *IEEE Intelligent Systems* 24 (2): 8--12.\n\nHammerbacher, Jeff. 2009. \"Information Platforms and the Rise of the\nData Scientist.\" In *Beautiful Data: The Stories Behind Elegant Data\nSolutions*, 73--84. O'Reilly Media Sebastopol, CA.\n\nHarmon, Dick. 2007. \"Something Seedy Is up When It Comes to BYU.\"\n*Deseret Morning News*, March 18, 2007.\nhttps://advance.lexis.com/document/?pdmfid=1516831&crid=9baeb68b-cede-40c7-b517-447b0532d0e3&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4N91-M3V0-TWHW-6263-00000-00&pdcontentcomponentid=164282&pdteaserkey=sr24&pditab=allpods&ecomp=gb63k&earg=sr24&prid=8420657d-9905-49d3-ac82-3e36a8870263.\n\nHastie, Trevor, Robert Tibshirani, and J. H Friedman. 2009. *The\nElements of Statistical Learning: Data Mining, Inference, and\nPrediction*.\n\nHayashi, Chikio. 1998a. *Data Science, Classification, and Related\nMethods: Proceedings of the Fifth Conference of the International\nFederation of Classification Societies (IFCS-96), Kobe, Japan, March\n27-30, 1996*. Kobe, Japan: Springer.\n\n---------. 1998b. \"What Is Data Science? Fundamental Concepts and a\nHeuristic Example.\" In *Data Science, Classification, and Related\nMethods*, edited by Chikio Hayashi, Keiji Yajima, Hans-Hermann Bock,\nNoboru Ohsumi, Yutaka Tanaka, and Yasumasa Baba, 40--51. Studies in\nClassification, Data Analysis, and Knowledge Organization. Springer\nJapan.\n\nHendry, David F. 1995. *Dynamic Econometrics*. Advanced Texts in\nEconometrics. New York: Oxford Univ Press.\nhttps://www.google.com/books/edition/Dynamic_Econometrics/XcWVN2-2ZqIC?hl=en&gbpv=1&dq=%22data+mining%22&pg=PA544&printsec=frontcover.\n\nHerman, Mark, Stephanie Rivera, Mills Stephen, Josh Sullivan, Peter\nGuerra, Alex Cosmas, Drew Farris, et al. 2013. \"Field Guide to Data\nScience.\" Booz Allen Hamilton Inc.\nhttps://www.boozallen.com/s/insight/publication/field-guide-to-data-science.html.\n\nHey, Tony, Stewart Tansley, and Kristin Tolle. 2009. *The Fourth\nParadigm: Data-Intensive Scientific Discovery*.\nhttps://www.microsoft.com/en-us/research/publication/fourth-paradigm-data-intensive-scientific-discovery/.\n\nHiggins, James J. 1999. \"Nonmathematical Statistics: A New Direction for\nthe Undergraduate Discipline.\" *The American Statistician* 53 (1): 1--6.\nhttps://doi.org/10.1080/00031305.1999.10474418.\n\nKettenring, Jon R. 1997a. \"The Birth, Life, and Death of Statistical\nDepartment. President's Corner.\" *AMSTAT NEWS* 245: 9--10.\n\n---------. 1997b. \"Shaping Statistics for Success in the 21st Century.\"\n*Journal of the American Statistical Association* 92 (440): 1229--34.\nhttps://doi.org/10.1080/01621459.1997.10473641.\n\nKusnetzky, Dan. 2010. \"What Is 'Big Data?'\" *ZDNet*, February 16, 2010.\nhttp://www.zdnet.com/blog/virtualization/what-is-big-data/1708.\n\nLaney, Doug. 2001. \"3d Data Management: Controlling Data Volume,\nVelocity and Variety.\" *META Group Research Note* 6: 70.\n\n---------. 2012. \"Defining and Differentiating the Role of the Data\nScientist.\" Gartner. March 25, 2012.\nhttps://web.archive.org/web/20120327163714/http://blogs.gartner.com/doug-laney/defining-and-differentiating-the-role-of-the-data-scientist/.\n\n*Library Journal*. 1977. Library Journal.\n\nLide, David R., and Gordon H. Wood. 2012. *CODATA \\@ 45 Years: The Story\nof the ICSU Committee on Data for Science and Technology (CODATA) from\n1966 to 2010*. Paris, France: CODATA.\nhttps://books.google.com/books/about/CODATA_45_Years.html?id=NjA8kgEACAAJ&utm_source=gb-gplus-shareCODATA.\n\nLohr, Steve. 2009. \"For Today's Graduate, Just One Word: Statistics.\"\n*The New York Times*, August 5, 2009, sec. Technology.\nhttps://www.nytimes.com/2009/08/06/technology/06stats.html.\n\n---------. 2014. \"For Big-Data Scientists, 'Janitor Work' Is Key Hurdle\nto Insights.\" *The New York Times*, August 18, 2014, sec. Technology.\nhttps://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html.\n\nLoukides, Mike. 2011. *What Is Data Science?* O'Reilly Media, Inc.\nhttps://books.google.com/books?hl=en&lr=&id=-OQ2q5JqOdEC&oi=fnd&pg=PT2&dq=%22data+science%22&ots=1Y7O922KDq&sig=yQ1XsyNG6eckn6oUjVjfvtNzKzY.\n\nLovell, Michael C. 1983. \"Data Mining.\" *The Review of Economics and\nStatistics* 65 (1): 1--12. https://doi.org/10.2307/1924403.\n\nMa, Rong. 2015. \"Schleiermacher's Hermeneutic Circle and Bayesian\nStatistics.\" *RongMa\\@Penn* (blog). November 28, 2015.\nhttps://rongma.wordpress.com/2015/11/28/schleiermachers-hermeneutic-circle-and-bayesian-statistics/.\n\nMartin, E. 1998. \"Anthropology and the Cultural Study of Science.\"\n*Science, Technology & Human Values* 23 (1): 24--44.\nhttps://doi.org/10.1177/016224399802300102.\n\nMason, Hilary, and Christopher Wiggins. 2010. \"A Taxonomy of Data\nScience.\" *Dataists* (blog). September 25, 2010.\nhttp://www.dataists.com/2010/09/a-taxonomy-of-data-science/.\n\nMcKinsey & Company. 2009. \"Hal Varian on How the Web Challenges\nManagers.\" *McKinsey & Company*, January 1, 2009.\nhttps://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/hal-varian-on-how-the-web-challenges-managers.\n\nMenzies, Tim, Ekrem Kocaguneli, Fayola Peters, Burak Turhan, and Leandro\nL. Minku. 2013. \"Data Science for Software Engineering.\" In *2013 35th\nInternational Conference on Software Engineering (ICSE)*, 1484--86.\nhttps://doi.org/10.1109/ICSE.2013.6606752.\n\nMiller, Claire Cain. 2013. \"Data Science: The Numbers of Our Lives.\"\n*The New York Times*, April 11, 2013, sec. Education.\nhttps://www.nytimes.com/2013/04/14/education/edlife/universities-offer-courses-in-a-hot-new-field-data-science.html.\n\nMills, C. Wright. 1940. \"Situated Actions and Vocabularies of Motive.\"\n*American Sociological Review* 5 (6): 904--13.\nhttps://doi.org/10.2307/2084524.\n\nMort Collins Ventures. n.d. \"Bio.\" *MCollins Ventures* (blog). Accessed\nJuly 16, 2020. http://www.mcollinsventures.com/bio/.\n\nNaur, Peter. 1966. \"The Science of Datalogy.\" *Communications of the\nACM* 9 (7): 485. https://doi.org/10.1145/365719.366510.\n\n---------. 1992. *Computing, a Human Activity*. ACM Press.\n\n---------. n.d. \"Peter Naur: Concise Survey of Computer Methods, 397 p.\"\nIntroduction to the Works of Peter Naur. n.d.\nhttp://www.naur.com/Conc.Surv.html.\n\n\"New Scientist.\" 1992, 1992.\n\n\"---------.\" 1995, 1995.\n\n\"---------.\" 1996, 1996.\n\n\"---------.\" 1999, 1999.\n\n\"---------.\" 2001, 2001.\n\nNorman, Donald A. 1993. \"Cognition in the Head and in the World: An\nIntroduction to the Special Issue on Situated Action.\" *Cognitive\nScience* 17 (1): 1--6. https://doi.org/10.1207/s15516709cog1701_1.\n\nOffice, Library of Congress Copyright. 1979. *Catalog of Copyright\nEntries. Third Series: 1977: July-December: Index*. Copyright Office,\nLibrary of Congress.\n\nOgaz, Juan A. 1989. \"Telemetry Data Processing at White Sands Missile\nRange,\" November. https://repository.arizona.edu/handle/10150/614840.\n\nOhsumi, Noboru. 1992. \"An Experimental System for Navigating Statistical\nMeta-Information --- The Meta-Stat Navigator.\" In *Computational\nStatistics*, edited by Yadolah Dodge and Joe Whittaker, 375--80.\nHeidelberg: Physica-Verlag HD.\nhttps://doi.org/10.1007/978-3-642-48678-4_48.\n\n---------. 1994. \"New Data and New Tools: A Hypermedia Environment for\nNavigating Statistical Knowledge in Data Science.\" In *New Approaches in\nClassification and Data Analysis*, 45--54. Berlin: Springer-Verlag.\n\n---------. 2000. \"From Data Analysis to Data Science.\" In *Data\nAnalysis, Classification, and Related Methods*, 329--34. Springer.\n\n---------. 2004. \"Memories of Chikio Hayashi and His Great Achievement.\"\nIn *ResearchGate*.\nhttps://www.researchgate.net/publication/268719699_Memories_of_Chikio_Hayashi_and_his_great_achievement_2004.\n\nPalmer, Richard E. 1969. *Hermeneutics: Interpretation Theory in\nSchleiermacher, Dilthey, Heidegger, and Gadamer*. Northwestern\nUniversity Press.\n\nParsons, Mark A. 2019. \"Revised Focus and Scope.\" *The Data Science\nJournal*, November 6, 2019. http://datascience.codata.org/.\n\nParzen, Emanuel. 1977. \"Nonparametric Statistical Data Science: A\nUnified Approach Based on Density Estimation and Testing for'White\nNoise'.\" STATE UNIV OF NEW YORK AT BUFFALO AMHERST STATISTICAL SCIENCE\nDIV.\n\n---------. 1979. \"Nonparametric Statistical Data Modeling.\" *Journal of\nthe American Statistical Association* 74 (365): 105--21.\nhttps://doi.org/10.2307/2286734.\n\nParzen, Emanuel, and Subhadeep Mukhopadhyay. 2013. \"LP Mixed Data\nScience : Outline of Theory.\" *ArXiv:1311.0562 \\[Math, Stat\\]*,\nNovember. http://arxiv.org/abs/1311.0562.\n\nPatil, D. J. 2011. \"Building Data Science Teams.\" *O'Reilly Radar*,\nSeptember 2011.\nhttp://radar.oreilly.com/2011/09/building-data-science-teams.html.\n\nPiatetsky, Gregory. 2013. \"Is Data Science The End of Statistics? A\nDiscussion.\" *KDnuggets* (blog). October 23, 2013.\nhttps://www.kdnuggets.com/is-data-science-the-end-of-statistics-a-discussion.html/.\n\nPiatetsky-Shapiro, Gregory. 1991. \"Knowledge Disovery in Real Databases:\nA Report on the IJCAI-89 Workshop.\" *AI Magazine*, January 1991.\n\nReason, Suspended, and Tom Rutten. 2018. *Predictive Hermeneutics*.\n\nRodriguez, Robert. 2012. \"Big Data and Better Data.\" *Amstat News*\n(blog). June 1, 2012.\nhttps://magazine.amstat.org/blog/2012/06/01/prescorner/.\n\nRodriguez, Robert, Marie Davidian, and Nathaniel Schenker. 2013. \"The\nASA and Big Data.\" *Amstat News* (blog). June 1, 2013.\nhttps://magazine.amstat.org/blog/2013/06/01/the-asa-and-big-data/.\n\nRooney, Ben. 2012. \"Big Data's Big Problem: Little Talent.\" *Wall Street\nJournal*, April 29, 2012, sec. Tech.\nhttps://online.wsj.com/article/SB10001424052702304723304577365700368073674.html.\n\nShannon, C. E. 1948. \"A Mathematical Theory of Communication.\" *Bell\nSystems Technical Journal* 27: 379--423 and 623--56.\n\nShapiro, Ehud, Stuart Rison, Andrew Phillips, Andrew Herbert, Editors,\nand Stephen Emmott. 2006. *Towards 2020 Science*. Microsoft.\nhttps://www.microsoft.com/en-us/research/publication/towards-2020-science-2/.\n\nShcherbakov, Maxim, Nataliya Shcherbakova, Adriaan Brebels, Timur\nJanovsky, and Valery Kamaev. 2014. \"Lean Data Science Research Life\nCycle: A Concept for Data Analysis Software Development.\" In\n*Knowledge-Based Software Engineering*, edited by Alla Kravets, Maxim\nShcherbakov, Marina Kultsova, and Tadashi Iijima, 708--16.\nCommunications in Computer and Information Science. Cham: Springer\nInternational Publishing. https://doi.org/10.1007/978-3-319-11854-3_61.\n\nSimberloff, Daniel, B. C. Barish, K. K. Droegemeier, D. Etter, N.\nFedoroff, K. Ford, L. Lanzerotti, A. Leshner, J. Lubchenco, and M.\nRossmann. 2005. \"Long-Lived Digital Data Collections: Enabling Research\nand Education in the 21st Century.\" *National Science Foundation*.\n\nSmith, F. 2006. \"Data Science as an Academic Discipline.\" *Data Science\nJournal* 5 (0): 163--64.\n\n*St. Louis Post-Dispatch*. 2014. \"Allen, Robert (Bob) E. Died July\n1st.,\" July 6, 2014.\nhttps://advance.lexis.com/api/document?collection=news&id=urn:contentItem:5CKR-KK01-DY37-30GF-00000-00&context=1516831.\n\nSuchman, Lucy A. 1987. *Plans and Situated Actions: The Problem of\nHuman-Machine Communication*. 2nd ed. Cambridge University Press.\n\nSwan, Alma, and Sheridan Brown. 2008. \"The Skills, Role and Career\nStructure of Data Scientists and Curators: An Assessment of Current\nPractice and Future Needs.\" Programme/Project deposit. September 2,\n2008. http://repository.jisc.ac.uk/245/.\n\nTargeted News Service. 2008. \"Data Scientist Joins Rensselaer Tetherless\nWorld Research Constellation.\" *Targeted News Service*, November 13,\n2008.\nhttps://advance.lexis.com/document/?pdmfid=1516831&crid=854408e9-c5a7-4f17-a0fb-7b790a719e8f&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4VD9-W4P0-TYCS-10KJ-00000-00&pdcontentcomponentid=299219&pdteaserkey=sr32&pditab=allpods&ecomp=gb63k&earg=sr32&prid=19e1f7de-2617-49de-93da-706f9a17e95e.\n\n*The New York Times*. 1966. \"Mohawk Data Sciences,\" July 30, 1966, sec.\nArchives.\nhttps://www.nytimes.com/1966/07/30/archives/mohawk-data-sciences.html.\n\nTukey, John W. 1962. \"The Future of Data Analysis.\" *The Annals of\nMathematical Statistics* 33 (1): 1--67.\n\n---------. 1979. \"Nonparametric Statistical Data Modeling: Comment.\"\n*Journal of the American Statistical Association* 74 (365): 121--22.\nhttps://doi.org/10.2307/2286735.\n\nUrban, Greg. 1993. *A Discourse-Centered Approach to Culture: Native\nSouth American Myths and Rituals*. University of Texas Press.\n\nVarian, Hal R. 2010. \"Computer Mediated Transactions.\" *American\nEconomic Review* 100 (2): 1--10. https://doi.org/10.1257/aer.100.2.1.\n\nVenkateswaran, S. V. 1963. \"News and Notes: Reorganization of AFCRL.\"\n*Bulletin of the American Meteorological Society* 44 (9): 548--629.\n\nWitt, Michael. 2008. \"Institutional Repositories and Research Data\nCuration in a Distributed Environment.\" *Library Trends* 57 (2):\n191--201.\n\nWu, C. F. Jeff. 1997. \"Statistics = Data Science?\"\n\nYau, Nathan. 2009a. \"Google's Chief Economist Hal Varian on Statistics\nand Data.\" *FlowingData* (blog). February 25, 2009.\nhttps://flowingdata.com/2009/02/25/googles-chief-economist-hal-varian-on-statistics-and-data/.\n\n---------. 2009b. \"Rise of the Data Scientist.\" *FlowingData* (blog).\nJune 4, 2009.\nhttps://flowingdata.com/2009/06/04/rise-of-the-data-scientist/.\n\nYu, Bin. 2014. \"Let Us Own Data Science.\" *Institute of Mathematical\nStatistics* (blog). October 1, 2014.\nhttps://imstat.org/2014/10/01/ims-presidential-address-let-us-own-data-science/.\n\nZhu, Yangyong, and Yun Xiong. 2015. \"Defining Data Science.\"\n*ArXiv:1501.05039 \\[Cs\\]*, January. http://arxiv.org/abs/1501.05039.\n\nZhu, Yangyong, Ning Zhong, and Yun Xiong. 2009. \"Data Explosion, Data\nNature and Dataology.\" In *Brain Informatics*, edited by Ning Zhong,\nKuncheng Li, Shengfu Lu, and Lin Chen, 147--58. Lecture Notes in\nComputer Science. Berlin, Heidelberg: Springer.\nhttps://doi.org/10.1007/978-3-642-04954-5_25.\n\nZuboff, Shoshana. 2019. *The Age of Surveillance Capitalism: The Fight\nfor a Human Future at the New Frontier of Power*. 1 edition. New York:\nPublicAffairs.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","number-sections":false,"output-file":"ds-from-1963-to-2012.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.262","comments":{"hypothesis":true},"bibliography":["../../references.bib"],"theme":["cosmo","../../default.css"],"editor":{"markdown":{"wrap":72}}},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"ds-from-1963-to-2012.pdf"},"language":{},"metadata":{"block-headings":true,"comments":{"hypothesis":true},"bibliography":["../../references.bib"],"editor":{"markdown":{"wrap":72}}},"extensions":{"book":{}}}}}